{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Финальая попытка улучшить показатели\n",
    "Максимум, что удалось выжать ранее\n",
    "- RMSE: 23465.1123\n",
    "- R² (коэффициент детерминации): 0.9211\n",
    "- Средний RMSE на кросс-валидации: 25687.30318717033\n",
    "\n",
    "В этой версии переймем лучшие практики из прошлых подходов: \n",
    "- удаление ненужных признаков интуитивных;\n",
    "- внедрим IterativeImputer, который использует RandomForestRegression для обучения модели для заполнения пропущенных числовых фич;\n",
    "- *из нового* - попробуем поэкспериментировать еще с фича инжинирнгом, но уже не просто что-то удалить или создать или запустить SequentialFeatureSelector на 20 часов для подбора наилучшей комбинации фич, который не дал ничего - а логически проанализировать фичи, возможно, что-то добавить, объединить, как-то более хитро нормализовать и т.д.\n",
    "- поэкспериментируем с борьбой с переобучением (ограничить максимальную глубину деревьев (например, 6-8 вместо 10-12 по умолчанию); параметр L2-регуляризации листьев (l2_leaf_reg) добавляет штраф на большие значения предсказаний в листьях; rsm (Random Subspace Method) = 0.8)\n",
    "- детектор переобучения – можно указать параметр od_type (например, Iter или IncToDec) и od_wait, чтобы модель автоматически прекращала обучение, как только ошибка на валидации начинает расти (ранняя остановка)\n",
    "- сгенерировать дополнительные синтетические данные: 1) Добавление шума к числовым признакам (Jittering) - к каждому числовому признаку можно добавить небольшое случайное гауссово отклонение (с очень малой дисперсией, чтобы не исказить порядок величин). 2) SMOTE (Synthetic Minority Over-sampling Technique) - генерация новых объектов как интерполяция между ближайшими соседями - пытаться генерировать новый дом как среднее (или случайную комбинацию) двух похожих домов из обучающей выборки, а цену назначить промежуточную. 3) Генеративные модели данных - Conditional Tabular GAN (CTGAN), генерative adversarial network для таблиц. CTGAN умеет создавать синтетические табличные данные, сохраняя распределения как категориальных, так и числовых признаков (можно обучить CTGAN на имеющихся 2000 объектов и сгенерировать, скажем, ещё 1000 «новых» домов. Далее объединить их с реальными для обучения CatBoost.)\n",
    "\n",
    "Важно(!) Правильная валидация – краеугольный камень при работе с небольшим датасетом. \n",
    "С маленькой выборкой целесообразно запускать многократную (repeated) кросс-валидацию – например, 5-кратную CV повторить 2-3 раза с разными разбиениями и усреднить результат. "
   ],
   "id": "f5d9c2d4f118d10c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:13.834856Z",
     "start_time": "2025-04-02T07:19:10.351822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, PowerTransformer, RobustScaler, QuantileTransformer, PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
    "\n",
    "# Вместо одного фиксированного разбиения на train/test используем стабильную стратегию кросс-валидации.\n",
    "# Используем тут Cross-validation, потому что:\n",
    "# \t•\tнужно надёжно сравнить несколько разных моделей или гиперпараметров и понять, какая модель стабильнее и лучше в целом.\n",
    "# \t•\tхотим избежать случайных удач или провалов, связанных с конкретным разбиением на train/test.\n",
    "# \t•\tвыбираем модель или гиперпараметры, которые потом будешь использовать для финального сабмишна на Kaggle.\n",
    "# Делаем эту оценку, чтобы в дальнейших блокнотах-улучшениях сравнивать более корректно.\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score, train_test_split\n",
    "\n",
    "# Используем IterativeImputer:\n",
    "# \t•\tОн итеративно заполняет все пропуски сразу.\n",
    "# \t•\tРаботает одновременно со всеми признаками, учитывая связи между ними.\n",
    "# \t•\tНе требует ручного управления порядком заполнения.\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from utils.data_manager import DataManager\n",
    "from utils.model_manager import ModelManager\n",
    "from utils.synth_generator import SimpleSyntheticGenerator\n",
    "from utils.syth_generator_gaussian import CombinedSyntheticGenerator\n",
    "from utils.synth_generator_CTGAN import OptimizedCTGAN"
   ],
   "id": "f89e99b93f5d37f6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:13.879234Z",
     "start_time": "2025-04-02T07:19:13.838806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Глобально включаем вывод Pandas для всех трансформеров ---\n",
    "# (Можно применять и к отдельным трансформерам/пайплайнам .set_output(transform=\"pandas\"))\n",
    "set_config(transform_output = \"pandas\")"
   ],
   "id": "c62cb4ef34fe76e8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.045913Z",
     "start_time": "2025-04-02T07:19:13.968246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dm = DataManager()\n",
    "mm = ModelManager()\n",
    "\n",
    "mlflow.sklearn.autolog()"
   ],
   "id": "24d322817b3c9443",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Загрузка данных",
   "id": "a26dae5f23766246"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.092217Z",
     "start_time": "2025-04-02T07:19:14.050655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = 'data/home-data-for-ml-course'\n",
    "train_data = pd.read_csv(data_path + '/train.csv')\n",
    "test_data = pd.read_csv(data_path + '/test.csv')"
   ],
   "id": "d5d199725a1cb4ca",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Предобработка данных ",
   "id": "6d0d92bad6559a2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1. Удаление ненужных столбцов",
   "id": "dd6d51577e7f2184"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.135978Z",
     "start_time": "2025-04-02T07:19:14.103314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "intuitively_bad_features = [\n",
    "    'LotShape',  # Общая форма участка\n",
    "    'LandContour',  # Рельеф участка\n",
    "    'LotConfig',  # Конфигурация участка\n",
    "    'LandSlope',  # Уклон участка\n",
    "    'MiscFeature',\n",
    "    'MiscVal',\n",
    "]\n",
    "bad_columns = dm.get_all_nan_cols(train_data)\n",
    "bad_columns.append('Id')\n",
    "bad_columns.extend(intuitively_bad_features)\n",
    "bad_columns"
   ],
   "id": "8e4c0eb45f61243a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'MiscFeature',\n",
       " 'MiscVal']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.202261Z",
     "start_time": "2025-04-02T07:19:14.166553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = train_data.drop(columns=bad_columns)\n",
    "train_data.head()"
   ],
   "id": "c50277d51792336f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley Utilities  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN    AllPub   \n",
       "1          20       RL         80.0     9600   Pave   NaN    AllPub   \n",
       "2          60       RL         68.0    11250   Pave   NaN    AllPub   \n",
       "3          70       RL         60.0     9550   Pave   NaN    AllPub   \n",
       "4          60       RL         84.0    14260   Pave   NaN    AllPub   \n",
       "\n",
       "  Neighborhood Condition1 Condition2  ... 3SsnPorch ScreenPorch  PoolArea  \\\n",
       "0      CollgCr       Norm       Norm  ...         0           0         0   \n",
       "1      Veenker      Feedr       Norm  ...         0           0         0   \n",
       "2      CollgCr       Norm       Norm  ...         0           0         0   \n",
       "3      Crawfor       Norm       Norm  ...         0           0         0   \n",
       "4      NoRidge       Norm       Norm  ...         0           0         0   \n",
       "\n",
       "   PoolQC  Fence  MoSold YrSold SaleType SaleCondition SalePrice  \n",
       "0     NaN    NaN       2   2008       WD        Normal    208500  \n",
       "1     NaN    NaN       5   2007       WD        Normal    181500  \n",
       "2     NaN    NaN       9   2008       WD        Normal    223500  \n",
       "3     NaN    NaN       2   2006       WD       Abnorml    140000  \n",
       "4     NaN    NaN      12   2008       WD        Normal    250000  \n",
       "\n",
       "[5 rows x 74 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Пробуем нагенерировать синтетические данные",
   "id": "620d040026ed3d05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.262387Z",
     "start_time": "2025-04-02T07:19:14.232652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Инициализация и обучение генератора\n",
    "# generator = SimpleSyntheticGenerator()\n",
    "# generator.fit(train_data)\n",
    "# \n",
    "# # Генерация синтетических данных\n",
    "# synthetic_df = generator.generate(count=1500)\n",
    "# \n",
    "# # Сохранение результатов\n",
    "# synthetic_df.to_csv('synthetic_data.csv', index=False)\n",
    "# \n",
    "# sdf = pd.read_csv('synthetic_data.csv')\n",
    "# # Объединяем с реальными данными\n",
    "# train_data = pd.concat([train_data, sdf], ignore_index=True)\n",
    "\n",
    "# Очень плохие результаты по коду выше"
   ],
   "id": "374dca13cc03980a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.320079Z",
     "start_time": "2025-04-02T07:19:14.286534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Инициализация и обучение генератора\n",
    "# generator = CombinedSyntheticGenerator(use_gaussian_copula=True)\n",
    "# generator.fit(train_data)\n",
    "# \n",
    "# # Генерация синтетических данных\n",
    "# synthetic_df = generator.generate(count=500)\n",
    "# \n",
    "# # Сохранение результатов\n",
    "# synthetic_df.to_csv('synthetic_data2.csv', index=False)\n",
    "# \n",
    "# sdf = pd.read_csv('synthetic_data2.csv')\n",
    "# # Объединяем с реальными данными\n",
    "# train_data = pd.concat([train_data, sdf], ignore_index=True)\n",
    "# train_data.shape\n",
    "\n",
    "# Решение выше дало потрясающие результаты RMSE, R2 без кроссвалидации\n",
    "# RMSE: 16184.623736498073\n",
    "# R²: 0.9581875788511584\n",
    "# и даже с кросс-валидацией чудно\n",
    "# Средний RMSE на многократной кросс-валидации: 14632.7328\n",
    "# Стандартное отклонение RMSE: 1422.7506\n",
    "# Но сабмишн на кагл показал ужасные результаты, получается - жесткий оверфиттинг. Что очевидно, учитывая, что 3к данных нагенерили."
   ],
   "id": "8088346f4b5d798d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.398773Z",
     "start_time": "2025-04-02T07:19:14.365073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Инициализация генератора с настроенными параметрами\n",
    "# ctgan_generator = OptimizedCTGAN(\n",
    "#     categorical_threshold=15,  # Настройте под ваши данные\n",
    "#     epochs=50,                 # Начните с малого значения\n",
    "#     batch_size=64,             # Оптимальный размер для стабильности\n",
    "#     generator_dim=(64, 64),    # Уменьшенные размеры для скорости\n",
    "#     discriminator_dim=(64, 64),\n",
    "#     embedding_dim=32,\n",
    "#     cuda=False,                # True если есть GPU\n",
    "#     verbose=True\n",
    "# )\n",
    "# \n",
    "# # Обучение модели\n",
    "# ctgan_generator.fit(train_data)\n",
    "# \n",
    "# # # Генерация данных\n",
    "# # synthetic_df = ctgan_generator.generate(count=1500)\n",
    "# # \n",
    "# # # Сохранение и использование\n",
    "# # synthetic_df.to_csv('synthetic_data_ctgan.csv', index=False)\n",
    "# # combined_data = pd.concat([train_data, synthetic_df], ignore_index=True)\n",
    "# # print(f\"Размер объединенных данных: {combined_data.shape}\")\n",
    "\n",
    "# Это решение так и не вышло запустить по причине того, что все зависает на 0 итерации."
   ],
   "id": "f0d815c427b41d9a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.460482Z",
     "start_time": "2025-04-02T07:19:14.431734Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_STATE = 42",
   "id": "4190d72e803ce7a3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.500436Z",
     "start_time": "2025-04-02T07:19:14.470019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = dm.split_data_set_to_x_y(train_data, 'SalePrice')\n",
    "print(X.shape, y.shape)"
   ],
   "id": "f33ce416dfe3979a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 73) (1460,)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.557909Z",
     "start_time": "2025-04-02T07:19:14.529321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Пытаемся еще пофичаинженерить\n",
    "# X['TotalSF'] = X['1stFlrSF'] + X['2ndFlrSF'] + X['TotalBsmtSF']\n",
    "# X['Age'] = X['YrSold'] - X['YearBuilt']\n",
    "# X['QualityIndex'] = X['OverallQual'] * X['OverallCond']\n",
    "# X['HasPool'] = (X['PoolArea'] > 0).astype(int)\n",
    "# X['Remodeled'] = (X['YearRemodAdd'] != X['YearBuilt']).astype(int)\n",
    "# X['TotalBathrooms'] = X['FullBath'] + 0.5 * X['HalfBath'] + X['BsmtFullBath'] + 0.5 * X['BsmtHalfBath']\n",
    "# X.shape\n",
    "# # Не дало улучшений"
   ],
   "id": "df267b426677e3cb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.596770Z",
     "start_time": "2025-04-02T07:19:14.560767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Еще пытаемся пофичаинженерить\n",
    "# X['Neighborhood_Qual'] = X['Neighborhood'] + '_' + X['OverallQual'].astype(str)\n",
    "# X['BldgType_Condition'] = X['BldgType'] + '_' + X['OverallCond'].astype(str)\n",
    "\n",
    "# И еще\n",
    "# Полезная жилая площадь на всех уровнях\n",
    "# X['UsefulSF'] = X['GrLivArea'] + X['TotalBsmtSF'] - X['LowQualFinSF']\n",
    "# \n",
    "# # Доля жилой площади в общей площади\n",
    "# X['LivingAreaRatio'] = X['GrLivArea'] / X['LotArea']\n",
    "# \n",
    "# # Отношение гаража к дому\n",
    "# X['GarageRatio'] = X['GarageArea'] / X['GrLivArea']\n",
    "# \n",
    "# # Отношение площади террас и крылец к жилой площади\n",
    "# X['PorchDeckArea'] = (X['WoodDeckSF'] + X['OpenPorchSF'] + X['EnclosedPorch'] +\n",
    "#                       X['3SsnPorch'] + X['ScreenPorch'])\n",
    "# X['PorchDeckRatio'] = X['PorchDeckArea'] / X['GrLivArea']\n",
    "\n",
    "# и Еще\n",
    "# X['IsNewHouse'] = (X['YrSold'] - X['YearBuilt'] <= 1).astype(int)\n",
    "# X['IsRecentRemodel'] = (X['YrSold'] - X['YearRemodAdd'] <= 5).astype(int)\n",
    "# X['GarageAge'] = X['YrSold'] - X['GarageYrBlt']\n",
    "# X['GarageAge'] = X['GarageAge'].fillna(X['GarageAge'].median())  # важно обработать NA\n",
    "\n",
    "# и еще\n",
    "X['Neighborhood_Zoning'] = X['Neighborhood'] + '_' + X['MSZoning']\n",
    "X['SaleType_Condition'] = X['SaleType'] + '_' + X['SaleCondition']\n",
    "# Получили прирост качества!\n",
    "\n",
    "# и еще\n",
    "# Объединяем несколько качественных признаков в единый числовой индекс:\n",
    "quality_dict = {'Ex': 5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.nan:0}\n",
    "X['TotalQualScore'] = (\n",
    "    X['ExterQual'].map(quality_dict) +\n",
    "    X['KitchenQual'].map(quality_dict) +\n",
    "    X['BsmtQual'].map(quality_dict) +\n",
    "    X['HeatingQC'].map(quality_dict) +\n",
    "    X['GarageQual'].map(quality_dict) +\n",
    "    X['FireplaceQu'].map(quality_dict)\n",
    ")\n",
    "# Получили значимый (-400 RMSE) прирост качества!\n",
    "\n",
    "# и еще\n",
    "# # Отношение площади террас и крылец к жилой площади\n",
    "X['PorchDeckArea'] = (X['WoodDeckSF'] + X['OpenPorchSF'] + X['EnclosedPorch'] +\n",
    "                      X['3SsnPorch'] + X['ScreenPorch'])\n",
    "X['HasFireplace'] = (X['Fireplaces'] > 0).astype(int)\n",
    "X['HasGarage'] = (~X['GarageType'].isna()).astype(int)\n",
    "X['HasFence'] = (~X['Fence'].isna()).astype(int)\n",
    "X['HasPorchDeck'] = (X['PorchDeckArea'] > 0).astype(int)\n",
    "# Получили значимый (-400 RMSE) прирост качества!\n"
   ],
   "id": "7b0a3a85076d673d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.636816Z",
     "start_time": "2025-04-02T07:19:14.609112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Функция для добавления полиномиальных признаков ---\n",
    "# Она будет использоваться в FunctionTransformer\n",
    "# def add_polynomial_features(df, poly_cols):\n",
    "#     \"\"\"\n",
    "#     Добавляет полиномиальные признаки 3-й степени для указанных колонок.\n",
    "#     Заполняет пропуски медианой перед генерацией.\n",
    "#     Удаляет исходные колонки, использованные для генерации.\n",
    "#     \"\"\"\n",
    "#     df_copy = df.copy()\n",
    "#     # Убедимся, что все нужные колонки есть в DataFrame\n",
    "#     cols_to_process = [col for col in poly_cols if col in df_copy.columns]\n",
    "#     if not cols_to_process:\n",
    "#          print(\"Warning: No columns found for polynomial feature generation.\")\n",
    "#          return df_copy # Возвращаем копию без изменений\n",
    "# \n",
    "#     df_subset = df_copy[cols_to_process]\n",
    "# \n",
    "#     # Заполняем пропуски медианой ТОЛЬКО для этих колонок\n",
    "#     # Важно: медиану лучше считать на трейне и передавать сюда,\n",
    "#     # но для простоты примера считаем на лету. Для пайплайна это ок.\n",
    "#     for col in cols_to_process:\n",
    "#          if df_subset[col].isnull().any():\n",
    "#                median_val = df_subset[col].median()\n",
    "#                df_subset[col] = df_subset[col].fillna(median_val)\n",
    "# \n",
    "#     # Создаем объект PolynomialFeatures\n",
    "#     poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
    "# \n",
    "#     # Обучаем и трансформируем подмножество данных\n",
    "#     poly_features_generated = poly.fit_transform(df_subset)\n",
    "# \n",
    "#     # Получаем имена новых признаков\n",
    "#     poly_feature_names = poly.get_feature_names_out(cols_to_process)\n",
    "# \n",
    "#     # Создаем DataFrame с новыми признаками\n",
    "#     df_poly_features = pd.DataFrame(poly_features_generated, columns=poly_feature_names, index=df_copy.index)\n",
    "# \n",
    "#     # Удаляем исходные колонки из копии\n",
    "#     df_copy = df_copy.drop(columns=cols_to_process)\n",
    "# \n",
    "#     # Объединяем исходный DataFrame (без старых колонок) с новыми полиномиальными\n",
    "#     df_final = pd.concat([df_copy, df_poly_features], axis=1)\n",
    "# \n",
    "#     print(f\"Polynomial features added. Total columns now: {df_final.shape[1]}\")\n",
    "#     return df_final\n",
    "# # Вроде дает небольшое улучшение RMSE"
   ],
   "id": "357b2ff2fefc0f87",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.678280Z",
     "start_time": "2025-04-02T07:19:14.648582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # --- Winsorizing (Ограничение выбросов) ---\n",
    "# Пример ДО встраивания в пайплайн\n",
    "# Как выбрать колонки и встроить в пайплайн?\n",
    "# Визуальный анализ: Построить гистограммы или box plot-ы для всех числовых признаков. Выбрать для Winsorizing только те, у которых явно видны длинные хвосты или отдельные точки далеко от основного распределения. GrLivArea, LotArea, TotalBsmtSF, 1stFlrSF, BsmtFinSF1 — частые кандидаты.\n",
    "# \n",
    "# Подбор квантилей: Вместо фиксированных 1%/99%, попробовать другие значения (например, 0.5%/99.5% или 2%/98%) и посмотреть на кросс-валидации, какой диапазон лучше работает для конкретного признака или группы признаков.\n",
    "# \n",
    "# Кастомный трансформер для пайплайна: Чтобы встроить Winsorizing в пайплайн sklearn и правильно обрабатывать данные при кросс-валидации (считать квантили на трейне, применять на тесте), нужно создать свой класс-трансформер.\n",
    "\n",
    "# cols_to_winsorize = X.select_dtypes(include=['float64', 'int64']).columns # Пример колонки\n",
    "# \n",
    "# for col_to_winsorize in cols_to_winsorize:\n",
    "#     # Определяем квантили (например, 1% и 99%)\n",
    "#     lower_quantile = X[col_to_winsorize].quantile(0.01)\n",
    "#     upper_quantile = X[col_to_winsorize].quantile(0.99)\n",
    "#     \n",
    "#     print(f\"\\nИсходные мин/макс для '{col_to_winsorize}': {X[col_to_winsorize].min()}/{X[col_to_winsorize].max()}\")\n",
    "#     print(f\"Нижний (1%) и верхний (99%) квантили: {lower_quantile:.2f} / {upper_quantile:.2f}\")\n",
    "#     \n",
    "#     # Применяем ограничение с помощью .clip()\n",
    "#     # Все значения ниже lower_quantile станут равны lower_quantile\n",
    "#     # Все значения выше upper_quantile станут равны upper_quantile\n",
    "#     X[col_to_winsorize + '_winsorized'] = X[col_to_winsorize].clip(lower=lower_quantile, upper=upper_quantile)\n",
    "#     \n",
    "#     print(f\"Мин/макс для '{col_to_winsorize}_winsorized': {X[col_to_winsorize + '_winsorized'].min()}/{X[col_to_winsorize + '_winsorized'].max()}\")\n",
    "#     print(\"---\")"
   ],
   "id": "196c58981cb6f858",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.719610Z",
     "start_time": "2025-04-02T07:19:14.690407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ОЧЕНЬ ВАЖНО убедиться, что набор признаков (X_submission) абсолютно совпадает с X по количеству и порядку колонок!\n",
    "X = X.sort_index(axis=1)\n",
    "feature_cols = X.columns"
   ],
   "id": "ef7e5c1f61d60bfb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2. Нормализация данных через ColumnTransformer и Pipeline\n",
    "В данном кейсе мы реализуем Заполнение числовых пропусков с помощью модели (Predictive imputation). Т.е. то, что пропущено в числовых признаках - будем заполнять не медианой или средним, а будем обучать модель, которая будет предсказывать пропуски (IterativeImputer + RandomForestRegressor)"
   ],
   "id": "40f0ad8b54c9e3db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.759375Z",
     "start_time": "2025-04-02T07:19:14.730874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Получение числовых колонок\n",
    "numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Получение нечисловых колонок (всех остальных)\n",
    "non_numeric_columns = X.select_dtypes(exclude=['float64', 'int64']).columns"
   ],
   "id": "33df412f412810b2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.816430Z",
     "start_time": "2025-04-02T07:19:14.771298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаем preprocessor с разными трансформерами для разных типов данных\n",
    "# Числовые данные пропущенные предсказываем с помощью модели RandomForestRegressor\n",
    "\n",
    "# --- Кастомный трансформер Winsorizer ---\n",
    "class Winsorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Применяет Winsorizing к указанным колонкам DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    quantile_range : tuple, optional (default=(0.01, 0.99))\n",
    "        Кортеж с нижним и верхним квантилями для ограничения.\n",
    "    columns : list\n",
    "        Список названий колонок, к которым нужно применить Winsorizing.\n",
    "    \"\"\"\n",
    "    def __init__(self, quantile_range=(0.01, 0.99), columns=None):\n",
    "        self.quantile_range = quantile_range\n",
    "        self.columns = columns\n",
    "        self.limits_ = {} # Словарь для хранения вычисленных квантилей\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Вычисляет квантили на обучающих данных.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Обучающие данные.\n",
    "        y : None\n",
    "            Игнорируется.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        if self.columns is None:\n",
    "            # Если колонки не указаны, применяем ко всем числовым\n",
    "            self.columns = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "        # Проверяем, что X - это DataFrame\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"Input X must be a pandas DataFrame\")\n",
    "\n",
    "        for col in self.columns:\n",
    "            if col in X.columns:\n",
    "                lower_quantile_val = X[col].quantile(self.quantile_range[0])\n",
    "                upper_quantile_val = X[col].quantile(self.quantile_range[1])\n",
    "                self.limits_[col] = (lower_quantile_val, upper_quantile_val)\n",
    "            else:\n",
    "                 print(f\"Warning: Column '{col}' not found in DataFrame during fit.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Применяет ограничение (clipping) к данным.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Данные для трансформации.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Трансформированные данные.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        # Проверяем, что X - это DataFrame\n",
    "        if not isinstance(X_copy, pd.DataFrame):\n",
    "             raise ValueError(\"Input X must be a pandas DataFrame\")\n",
    "\n",
    "        for col in self.columns:\n",
    "            if col in self.limits_: # Применяем только если квантили были посчитаны\n",
    "                 if col in X_copy.columns:\n",
    "                     lower_limit, upper_limit = self.limits_[col]\n",
    "                     X_copy[col] = X_copy[col].clip(lower=lower_limit, upper=upper_limit)\n",
    "                 else:\n",
    "                     print(f\"Warning: Column '{col}' not found in DataFrame during transform.\")\n",
    "            # Если колонки не было в fit, ничего не делаем с ней\n",
    "        return X_copy\n",
    "    \n",
    "\n",
    "# --- Создаем трансформер на основе функции полиномиальной ---\n",
    "# validate=False, т.к. функция меняет количество и названия колонок\n",
    "# poly_features_cols = ['GrLivArea', 'TotalBsmtSF', 'YearBuilt', 'LotArea']  # Колонки для полиномиальных признаков\n",
    "# polynomial_transformer = FunctionTransformer(\n",
    "#     add_polynomial_features,\n",
    "#     kw_args={'poly_cols': poly_features_cols}, # Передаем список колонок в функцию\n",
    "#     validate=False\n",
    "# )\n",
    "# Кроме переобучение - ничего не дали полиномиальные признаки, хоть текущий RMSE улучшился сильно, а самбишн - плохой стал\n",
    "\n",
    "\n",
    "# Пайплайн для числовых признаков (итеративное заполнение)\n",
    "# Колонки, которые мы хотим \"винсоризировать\" (выбираем на основе анализа)\n",
    "cols_to_winsorize = ['GrLivArea', 'LotArea', 'TotalBsmtSF', '1stFlrSF']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=50, random_state=RANDOM_STATE),\n",
    "        max_iter=10,\n",
    "        random_state=RANDOM_STATE\n",
    "    )),\n",
    "    # Применяем Winsorizer ПОСЛЕ импутации\n",
    "    # ('winsorizer', Winsorizer(quantile_range=(0.01, 0.99), columns=cols_to_winsorize)),\n",
    "    # Опционально: добавляем масштабирование ПОСЛЕ winsorizing\n",
    "    # ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Пайплайн для категориальных признаков (заполнение частым значением и кодирование)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    # ('target_enc', TargetEncoder(smoothing=10, min_samples_leaf=4, handle_unknown='value', handle_missing='value'))\n",
    "])\n",
    "\n",
    "# --- Объединяем препроцессоры ---\n",
    "# Применяем к исходным числовым и категориальным колонкам\n",
    "# Полиномиальные признаки будут добавлены ДО этого шага\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Применяем к исходным числовым колонкам\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        # Применяем к исходным категориальным колонкам\n",
    "        ('cat', categorical_transformer, non_numeric_columns)\n",
    "    ],\n",
    "    remainder='drop',   # 'passthrough' сохранит полиномиальные и другие колонки, которые не были ни числовыми, ни категориальными ИЗНАЧАЛЬНО\n",
    "    verbose_feature_names_out=False # Чтобы имена колонок не менялись на 'num__colname' и т.д.\n",
    ")\n",
    "\n",
    "default_params = {\n",
    "    'iterations': 1000, \n",
    "    'learning_rate': 0.05, \n",
    "    'depth': 6, \n",
    "    'loss_function': 'RMSE', \n",
    "    'verbose': 0, \n",
    "    'random_seed': RANDOM_STATE,\n",
    "}\n",
    "# --- Финальный пайплайн ---\n",
    "# Добавляем polynomial_transformer как ПЕРВЫЙ шаг\n",
    "final_pipeline = Pipeline([\n",
    "    # ('poly_features', polynomial_transformer), # Шаг 1: Добавляем полиномиальные признаки\n",
    "    ('preprocessing', preprocessor),          # Шаг 2: Применяем остальной препроцессинг\n",
    "    ('model', CatBoostRegressor(**default_params))  # Шаг 3: Модель\n",
    "])"
   ],
   "id": "4b3278e6b55e1980",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3. Разбиение данных на обучающую и тестовую выборки",
   "id": "aa30fb29dd65de6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.910902Z",
     "start_time": "2025-04-02T07:19:14.866514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Один из самых эффективных приемов для задач прогнозирования цен на недвижимость: Выявление и устранение аномальных значений (Логарифмическая трансформация: Применение log1p() (натуральный логарифм от значения плюс 1) к ценам: Сжимает шкалу, приближая распределение к нормальному; Уменьшает влияние выбросов без их удаления) и пр.\n",
    "# # Логарифмирование целевой переменной\n",
    "# y_log = np.log1p(y)\n",
    "# \n",
    "# # Разделение на обучающую и тестовую выборки\n",
    "# X_train, X_test, y_log_train, y_log_test = train_test_split(\n",
    "#     X, y_log, test_size=0.3, random_state=RANDOM_STATE\n",
    "# )\n",
    "# \n",
    "# # Обучение модели на логарифмированных ценах\n",
    "# final_pipeline.fit(X_train, y_log_train)\n",
    "# \n",
    "# # Предсказание (в логарифмической шкале)\n",
    "# y_log_pred = final_pipeline.predict(X_test)\n",
    "# \n",
    "# # Обратное преобразование для возврата к исходной шкале\n",
    "# y_pred = np.expm1(y_log_pred)\n",
    "# y_test_original = np.expm1(y_log_test)\n",
    "# \n",
    "# # Расчет метрик на исходной шкале\n",
    "# print(\"RMSE:\", root_mean_squared_error(y_test_original, y_pred))\n",
    "# print(\"R²:\", r2_score(y_test_original, y_pred))\n",
    "\n",
    "# Показатели не улучшились\n",
    "# RMSE: 24355.361915626483\n",
    "# R²: 0.9149934531746243\n"
   ],
   "id": "94041d050db97c09",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:14.998393Z",
     "start_time": "2025-04-02T07:19:14.968405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Попробуем другие преобразования Y\n",
    "# y_sqrt = np.sqrt(y)\n",
    "# \n",
    "# # Разделение на обучающую и тестовую выборки\n",
    "# X_train, X_test, y_sqrt_train, y_sqrt_test = train_test_split(\n",
    "#     X, y_sqrt, test_size=0.3, random_state=RANDOM_STATE\n",
    "# )\n",
    "# \n",
    "# # Обучение модели\n",
    "# final_pipeline.fit(X_train, y_sqrt_train)\n",
    "# \n",
    "# # Предсказание\n",
    "# y_sqrt_pred = final_pipeline.predict(X_test)\n",
    "# \n",
    "# # Обратное преобразование для возврата к исходной шкале\n",
    "# y_pred = y_sqrt_pred ** 2\n",
    "# y_test_original = y_sqrt_test ** 2\n",
    "# \n",
    "# # Расчет метрик на исходной шкале\n",
    "# print(\"RMSE:\", root_mean_squared_error(y_test_original, y_pred))\n",
    "# print(\"R²:\", r2_score(y_test_original, y_pred))\n",
    "\n",
    "# Показатели лучше, чем в log1p версии, но не улучшились от идеала\n",
    "# RMSE: 24016.628174145026\n",
    "# R²: 0.9173415479046967\n"
   ],
   "id": "ff5ec66d480c5ce5",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:15.080734Z",
     "start_time": "2025-04-02T07:19:15.051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Попробуем другие преобразования Y\n",
    "# from scipy import stats\n",
    "# from scipy.special import inv_boxcox\n",
    "# y_boxcox, lambda_param = stats.boxcox(y)\n",
    "# \n",
    "# # Разделение на обучающую и тестовую выборки\n",
    "# X_train, X_test, y_bxcx_train, y_bxcx_test = train_test_split(\n",
    "#     X, y_boxcox, test_size=0.3, random_state=RANDOM_STATE\n",
    "# )\n",
    "# \n",
    "# # Обучение модели\n",
    "# final_pipeline.fit(X_train, y_bxcx_train)\n",
    "# \n",
    "# # Предсказание \n",
    "# y_bxcx_pred = final_pipeline.predict(X_test)\n",
    "# \n",
    "# # Обратное преобразование для возврата к исходной шкале\n",
    "# y_pred = inv_boxcox(y_bxcx_pred, lambda_param)\n",
    "# y_test_original = inv_boxcox(y_bxcx_test, lambda_param)\n",
    "# \n",
    "# # Расчет метрик на исходной шкале\n",
    "# print(\"RMSE:\", root_mean_squared_error(y_test_original, y_pred))\n",
    "# print(\"R²:\", r2_score(y_test_original, y_pred))\n",
    "\n",
    "# Еще хуже, чем у log1p показатели\n",
    "# RMSE: 24708.20382416625\n",
    "# R²: 0.9125125919582991"
   ],
   "id": "17e3313d9cadb835",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:15.163972Z",
     "start_time": "2025-04-02T07:19:15.131810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Попробуем другие преобразования Y\n",
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# qt = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "# y_transformed = qt.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "# \n",
    "# # Разделение на обучающую и тестовую выборки\n",
    "# X_train, X_test, y_qt_train, y_qt_test = train_test_split(\n",
    "#     X, y_transformed, test_size=0.3, random_state=RANDOM_STATE\n",
    "# )\n",
    "# \n",
    "# # Обучение модели\n",
    "# final_pipeline.fit(X_train, y_qt_train)\n",
    "# \n",
    "# # Предсказание \n",
    "# y_qt_pred = final_pipeline.predict(X_test)\n",
    "# \n",
    "# # Обратное преобразование для возврата к исходной шкале\n",
    "# y_pred = qt.inverse_transform(y_qt_pred.reshape(-1, 1)).ravel()\n",
    "# y_test_original = qt.inverse_transform(y_qt_test.reshape(-1, 1)).ravel()\n",
    "# \n",
    "# # Расчет метрик на исходной шкале\n",
    "# print(\"RMSE:\", root_mean_squared_error(y_test_original, y_pred))\n",
    "# print(\"R²:\", r2_score(y_test_original, y_pred))\n",
    "\n",
    "# Еще хуже, чем у log1p показатели\n",
    "# RMSE: 25475.711594983382\n",
    "# R²: 0.9069929548806451"
   ],
   "id": "675ab84eca935836",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:15.240891Z",
     "start_time": "2025-04-02T07:19:15.211204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "# \n",
    "# # Выявление и обработка выбросов в признаках\n",
    "# def remove_outliers_safe(df, y, threshold=3):\n",
    "#     \"\"\"\n",
    "#     Удаляет выбросы на основе z-score, но более безопасным способом\n",
    "#     \"\"\"\n",
    "#     df_clean = df.copy()\n",
    "#     y_clean = y.copy()\n",
    "#     \n",
    "#     # Вычисляем z-score для каждого столбца\n",
    "#     outliers_mask = np.zeros(len(df_clean), dtype=bool)\n",
    "#     \n",
    "#     for col in df_clean.select_dtypes(include=['float64', 'int64']).columns:\n",
    "#         # Проверяем, что в столбце достаточно уникальных значений для z-score\n",
    "#         if len(df_clean[col].unique()) > 5:  # Защита от категориальных данных с числовыми кодами\n",
    "#             # Используем try-except для защиты от ошибок при расчете z-score\n",
    "#             try:\n",
    "#                 # Игнорируем NaN значения при расчете z-score\n",
    "#                 with np.errstate(all='ignore'):  # Подавляем предупреждения\n",
    "#                     z_scores = np.abs(stats.zscore(df_clean[col], nan_policy='omit'))\n",
    "#                     col_outliers = np.logical_and(~np.isnan(z_scores), z_scores > threshold)\n",
    "#                     outliers_mask = np.logical_or(outliers_mask, col_outliers)\n",
    "#             except:\n",
    "#                 print(f\"Не удалось рассчитать z-score для столбца {col}. Пропускаем.\")\n",
    "#                 continue\n",
    "#     \n",
    "#     # Процент выбросов\n",
    "#     outlier_percentage = outliers_mask.mean() * 100\n",
    "#     print(f\"Обнаружено {outlier_percentage:.2f}% выбросов.\")\n",
    "#     \n",
    "#     # Если процент выбросов слишком велик, ограничиваемся верхним пределом\n",
    "#     max_outlier_percentage = 20  # Максимальный % строк, которые можно удалить\n",
    "#     if outlier_percentage > max_outlier_percentage:\n",
    "#         print(f\"Слишком много выбросов! Ограничиваем удаление до {max_outlier_percentage}%\")\n",
    "#         # Выбираем только самые экстремальные выбросы\n",
    "#         z_scores_all = np.zeros((len(df_clean), len(df_clean.select_dtypes(include=['float64', 'int64']).columns)))\n",
    "#         \n",
    "#         for i, col in enumerate(df_clean.select_dtypes(include=['float64', 'int64']).columns):\n",
    "#             if len(df_clean[col].unique()) > 5:\n",
    "#                 try:\n",
    "#                     z_scores_all[:, i] = np.abs(stats.zscore(df_clean[col], nan_policy='omit'))\n",
    "#                 except:\n",
    "#                     continue\n",
    "#         \n",
    "#         # Максимальное отклонение по z-score для каждой строки\n",
    "#         max_z_scores = np.nanmax(z_scores_all, axis=1)\n",
    "#         # Сортируем индексы по убыванию z-score\n",
    "#         sorted_indices = np.argsort(-max_z_scores)\n",
    "#         # Выбираем индексы верхних n% строк для удаления\n",
    "#         n_to_remove = int(len(df_clean) * max_outlier_percentage / 100)\n",
    "#         indices_to_remove = sorted_indices[:n_to_remove]\n",
    "#         outliers_mask = np.zeros(len(df_clean), dtype=bool)\n",
    "#         outliers_mask[indices_to_remove] = True\n",
    "#     \n",
    "#     # Удаляем выбросы\n",
    "#     df_cleaned = df_clean[~outliers_mask].reset_index(drop=True)\n",
    "#     y_cleaned = y_clean[~outliers_mask].reset_index(drop=True)\n",
    "#     \n",
    "#     print(f\"Размер исходной выборки: {len(df_clean)}\")\n",
    "#     print(f\"Размер очищенной выборки: {len(df_cleaned)}\")\n",
    "#     \n",
    "#     return df_cleaned, y_cleaned\n",
    "# \n",
    "# # Применяем функцию\n",
    "# X_clean, y_clean = remove_outliers_safe(X, y, threshold=3)\n",
    "# X, y = X_clean, y_clean\n",
    "\n",
    "# Выводы: очистка аномальных данных урезала дата-сет, упростила его, поэтому показатели улучшились сильно, даже на CV, но не на сабмишне, где показатели ухудшились. Типичный оверфиттинг."
   ],
   "id": "504748d35010c3b5",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:15.332766Z",
     "start_time": "2025-04-02T07:19:15.300565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Катбуст сам выбирает даныне для валидации, поэтому отсекаем данные только для теста\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Проверка размера полученных наборов\n",
    "print(f'Train size: {len(X_train)}')\n",
    "print(f'Test size: {len(X_test)}')"
   ],
   "id": "f9f1987f2c3d916b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1022\n",
      "Test size: 438\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:19:32.245981Z",
     "start_time": "2025-04-02T07:19:16.458515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.set_experiment(\"Advanced Feature Engineering\")\n",
    "with mlflow.start_run():\n",
    "    final_pipeline.fit(X_train, y_train)\n",
    "    results = mm.evaluate_regression(final_pipeline, X_test, y_test)\n",
    "    \n",
    "    mlflow.log_metric(\"RMSE_manual\", results['RMSE'])\n",
    "    mlflow.log_metric(\"MAE_manual\", results['MAE'])\n",
    "    mlflow.log_metric(\"MAPE_manual\", results['MAPE'])"
   ],
   "id": "ded3695a3d1a095b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 11:19:16 INFO mlflow.tracking.fluent: Experiment with name 'Advanced Feature Engineering' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.9261\n",
      "MSE:      515628859.6444\n",
      "RMSE:     22707.4626\n",
      "MAE:      13695.7936\n",
      "MSLE:     0.0141\n",
      "RMSLE:    0.1187\n",
      "MAPE:     0.0817\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Стремимся к:\n",
    "- R2 Score: 0.9261\n",
    "- MSE:      515628859.6444\n",
    "- RMSE:     22707.4626\n",
    "- MAE:      13695.7936\n",
    "- MSLE:     0.0141\n",
    "- RMSLE:    0.1187\n",
    "- MAPE:     0.0817"
   ],
   "id": "d7e1cfa3027181c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:55:20.406949Z",
     "start_time": "2025-04-01T19:55:15.946863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаем объект многократной кросс-валидации\n",
    "# n_splits=5 - количество фолдов\n",
    "# n_repeats=3 - количество повторений всей процедуры\n",
    "# random_state для воспроизводимости результатов\n",
    "repeated_cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Запускаем кросс-валидацию\n",
    "scores = cross_val_score(final_pipeline, X, y, \n",
    "                         scoring='neg_root_mean_squared_error', \n",
    "                         cv=repeated_cv)\n",
    "\n",
    "# Преобразуем отрицательные значения в положительные\n",
    "rmse_scores = -scores\n",
    "\n",
    "# Выводим результаты\n",
    "print(f\"Все значения RMSE: {rmse_scores}\")\n",
    "print(f\"Средний RMSE на многократной кросс-валидации: {rmse_scores.mean():.4f}\")\n",
    "print(f\"Стандартное отклонение RMSE: {rmse_scores.std():.4f}\")"
   ],
   "id": "6e6afa6d80013c7b",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m repeated_cv = RepeatedKFold(n_splits=\u001B[32m5\u001B[39m, n_repeats=\u001B[32m3\u001B[39m, random_state=RANDOM_STATE)\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# Запускаем кросс-валидацию\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m scores = \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfinal_pipeline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m                         \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mneg_root_mean_squared_error\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m                         \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepeated_cv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# Преобразуем отрицательные значения в положительные\u001B[39;00m\n\u001B[32m     13\u001B[39m rmse_scores = -scores\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    212\u001B[39m         skip_parameter_validation=(\n\u001B[32m    213\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    214\u001B[39m         )\n\u001B[32m    215\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    219\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    222\u001B[39m     msg = re.sub(\n\u001B[32m    223\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    224\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    225\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    226\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:684\u001B[39m, in \u001B[36mcross_val_score\u001B[39m\u001B[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001B[39m\n\u001B[32m    681\u001B[39m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[32m    682\u001B[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001B[32m--> \u001B[39m\u001B[32m684\u001B[39m cv_results = \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    685\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    686\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    687\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    688\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    689\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mscore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    690\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    691\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    692\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    693\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    694\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    695\u001B[39m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m=\u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    696\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    697\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[33m\"\u001B[39m\u001B[33mtest_score\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    212\u001B[39m         skip_parameter_validation=(\n\u001B[32m    213\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    214\u001B[39m         )\n\u001B[32m    215\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    219\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    222\u001B[39m     msg = re.sub(\n\u001B[32m    223\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    224\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    225\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    226\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:411\u001B[39m, in \u001B[36mcross_validate\u001B[39m\u001B[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[39m\n\u001B[32m    408\u001B[39m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[32m    409\u001B[39m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[32m    410\u001B[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001B[32m--> \u001B[39m\u001B[32m411\u001B[39m results = \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    412\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    414\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    415\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    416\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    417\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    418\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    419\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    420\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    421\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    422\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscore_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    423\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    424\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    425\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    426\u001B[39m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m=\u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    427\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    428\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\n\u001B[32m    429\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    431\u001B[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[32m    433\u001B[39m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[32m    434\u001B[39m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[32m    435\u001B[39m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    137\u001B[39m     config = {}\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:866\u001B[39m, in \u001B[36m_fit_and_score\u001B[39m\u001B[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[39m\n\u001B[32m    864\u001B[39m         estimator.fit(X_train, **fit_params)\n\u001B[32m    865\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m866\u001B[39m         \u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[32m    870\u001B[39m     fit_time = time.time() - start_time\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/pipeline.py:654\u001B[39m, in \u001B[36mPipeline.fit\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m    647\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    648\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe `transform_input` parameter can only be set if metadata \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    649\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mrouting is enabled. You can enable metadata routing using \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    650\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    651\u001B[39m     )\n\u001B[32m    653\u001B[39m routed_params = \u001B[38;5;28mself\u001B[39m._check_method_params(method=\u001B[33m\"\u001B[39m\u001B[33mfit\u001B[39m\u001B[33m\"\u001B[39m, props=params)\n\u001B[32m--> \u001B[39m\u001B[32m654\u001B[39m Xt = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    655\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(\u001B[33m\"\u001B[39m\u001B[33mPipeline\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m._log_message(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.steps) - \u001B[32m1\u001B[39m)):\n\u001B[32m    656\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._final_estimator != \u001B[33m\"\u001B[39m\u001B[33mpassthrough\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/pipeline.py:588\u001B[39m, in \u001B[36mPipeline._fit\u001B[39m\u001B[34m(self, X, y, routed_params, raw_params)\u001B[39m\n\u001B[32m    581\u001B[39m \u001B[38;5;66;03m# Fit or load from cache the current transformer\u001B[39;00m\n\u001B[32m    582\u001B[39m step_params = \u001B[38;5;28mself\u001B[39m._get_metadata_for_step(\n\u001B[32m    583\u001B[39m     step_idx=step_idx,\n\u001B[32m    584\u001B[39m     step_params=routed_params[name],\n\u001B[32m    585\u001B[39m     all_params=raw_params,\n\u001B[32m    586\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m588\u001B[39m X, fitted_transformer = \u001B[43mfit_transform_one_cached\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    589\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcloned_transformer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    590\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    591\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    592\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    593\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmessage_clsname\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mPipeline\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    594\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_log_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_idx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    595\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstep_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    596\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    597\u001B[39m \u001B[38;5;66;03m# Replace the transformer of the step with the fitted\u001B[39;00m\n\u001B[32m    598\u001B[39m \u001B[38;5;66;03m# transformer. This is necessary when loading the transformer\u001B[39;00m\n\u001B[32m    599\u001B[39m \u001B[38;5;66;03m# from the cache.\u001B[39;00m\n\u001B[32m    600\u001B[39m \u001B[38;5;28mself\u001B[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/joblib/memory.py:312\u001B[39m, in \u001B[36mNotMemorizedFunc.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    311\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m312\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/pipeline.py:1551\u001B[39m, in \u001B[36m_fit_transform_one\u001B[39m\u001B[34m(transformer, X, y, weight, message_clsname, message, params)\u001B[39m\n\u001B[32m   1549\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[32m   1550\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[33m\"\u001B[39m\u001B[33mfit_transform\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1551\u001B[39m         res = \u001B[43mtransformer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfit_transform\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1552\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1553\u001B[39m         res = transformer.fit(X, y, **params.get(\u001B[33m\"\u001B[39m\u001B[33mfit\u001B[39m\u001B[33m\"\u001B[39m, {})).transform(\n\u001B[32m   1554\u001B[39m             X, **params.get(\u001B[33m\"\u001B[39m\u001B[33mtransform\u001B[39m\u001B[33m\"\u001B[39m, {})\n\u001B[32m   1555\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    317\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m     data_to_wrap = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    321\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    322\u001B[39m         return_tuple = (\n\u001B[32m    323\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    324\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    325\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1001\u001B[39m, in \u001B[36mColumnTransformer.fit_transform\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m    998\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    999\u001B[39m     routed_params = \u001B[38;5;28mself\u001B[39m._get_empty_routing()\n\u001B[32m-> \u001B[39m\u001B[32m1001\u001B[39m result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_func_on_transformers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1002\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1003\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1004\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_fit_transform_one\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1005\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumn_as_labels\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1006\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1007\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1009\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result:\n\u001B[32m   1010\u001B[39m     \u001B[38;5;28mself\u001B[39m._update_fitted_transformers([])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:910\u001B[39m, in \u001B[36mColumnTransformer._call_func_on_transformers\u001B[39m\u001B[34m(self, X, y, func, column_as_labels, routed_params)\u001B[39m\n\u001B[32m    898\u001B[39m             extra_args = {}\n\u001B[32m    899\u001B[39m         jobs.append(\n\u001B[32m    900\u001B[39m             delayed(func)(\n\u001B[32m    901\u001B[39m                 transformer=clone(trans) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fitted \u001B[38;5;28;01melse\u001B[39;00m trans,\n\u001B[32m   (...)\u001B[39m\u001B[32m    907\u001B[39m             )\n\u001B[32m    908\u001B[39m         )\n\u001B[32m--> \u001B[39m\u001B[32m910\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    912\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    913\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mExpected 2D array, got 1D array instead\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    137\u001B[39m     config = {}\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/pipeline.py:1551\u001B[39m, in \u001B[36m_fit_transform_one\u001B[39m\u001B[34m(transformer, X, y, weight, message_clsname, message, params)\u001B[39m\n\u001B[32m   1549\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[32m   1550\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[33m\"\u001B[39m\u001B[33mfit_transform\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1551\u001B[39m         res = \u001B[43mtransformer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfit_transform\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1552\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1553\u001B[39m         res = transformer.fit(X, y, **params.get(\u001B[33m\"\u001B[39m\u001B[33mfit\u001B[39m\u001B[33m\"\u001B[39m, {})).transform(\n\u001B[32m   1554\u001B[39m             X, **params.get(\u001B[33m\"\u001B[39m\u001B[33mtransform\u001B[39m\u001B[33m\"\u001B[39m, {})\n\u001B[32m   1555\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/pipeline.py:730\u001B[39m, in \u001B[36mPipeline.fit_transform\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m    724\u001B[39m last_step_params = \u001B[38;5;28mself\u001B[39m._get_metadata_for_step(\n\u001B[32m    725\u001B[39m     step_idx=\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m) - \u001B[32m1\u001B[39m,\n\u001B[32m    726\u001B[39m     step_params=routed_params[\u001B[38;5;28mself\u001B[39m.steps[-\u001B[32m1\u001B[39m][\u001B[32m0\u001B[39m]],\n\u001B[32m    727\u001B[39m     all_params=params,\n\u001B[32m    728\u001B[39m )\n\u001B[32m    729\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(last_step, \u001B[33m\"\u001B[39m\u001B[33mfit_transform\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m730\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlast_step\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    731\u001B[39m \u001B[43m        \u001B[49m\u001B[43mXt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mlast_step_params\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfit_transform\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m    732\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m last_step.fit(Xt, y, **last_step_params[\u001B[33m\"\u001B[39m\u001B[33mfit\u001B[39m\u001B[33m\"\u001B[39m]).transform(\n\u001B[32m    735\u001B[39m         Xt, **last_step_params[\u001B[33m\"\u001B[39m\u001B[33mtransform\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    736\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    317\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m     data_to_wrap = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    321\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    322\u001B[39m         return_tuple = (\n\u001B[32m    323\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    324\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    325\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/impute/_iterative.py:859\u001B[39m, in \u001B[36mIterativeImputer.fit_transform\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m    855\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m feat_idx \u001B[38;5;129;01min\u001B[39;00m ordered_idx:\n\u001B[32m    856\u001B[39m     neighbor_feat_idx = \u001B[38;5;28mself\u001B[39m._get_neighbor_feat_idx(\n\u001B[32m    857\u001B[39m         n_features, feat_idx, abs_corr_mat\n\u001B[32m    858\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m859\u001B[39m     Xt, estimator = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_impute_one_feature\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    860\u001B[39m \u001B[43m        \u001B[49m\u001B[43mXt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    861\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmask_missing_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    862\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfeat_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    863\u001B[39m \u001B[43m        \u001B[49m\u001B[43mneighbor_feat_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    864\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    865\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfit_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    866\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    867\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    868\u001B[39m     estimator_triplet = _ImputerTriplet(\n\u001B[32m    869\u001B[39m         feat_idx, neighbor_feat_idx, estimator\n\u001B[32m    870\u001B[39m     )\n\u001B[32m    871\u001B[39m     \u001B[38;5;28mself\u001B[39m.imputation_sequence_.append(estimator_triplet)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/impute/_iterative.py:427\u001B[39m, in \u001B[36mIterativeImputer._impute_one_feature\u001B[39m\u001B[34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode, params)\u001B[39m\n\u001B[32m    417\u001B[39m     X_train = _safe_indexing(\n\u001B[32m    418\u001B[39m         _safe_indexing(X_filled, neighbor_feat_idx, axis=\u001B[32m1\u001B[39m),\n\u001B[32m    419\u001B[39m         ~missing_row_mask,\n\u001B[32m    420\u001B[39m         axis=\u001B[32m0\u001B[39m,\n\u001B[32m    421\u001B[39m     )\n\u001B[32m    422\u001B[39m     y_train = _safe_indexing(\n\u001B[32m    423\u001B[39m         _safe_indexing(X_filled, feat_idx, axis=\u001B[32m1\u001B[39m),\n\u001B[32m    424\u001B[39m         ~missing_row_mask,\n\u001B[32m    425\u001B[39m         axis=\u001B[32m0\u001B[39m,\n\u001B[32m    426\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m427\u001B[39m     \u001B[43mestimator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    429\u001B[39m \u001B[38;5;66;03m# if no missing values, don't predict\u001B[39;00m\n\u001B[32m    430\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np.sum(missing_row_mask) == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:487\u001B[39m, in \u001B[36mBaseForest.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    476\u001B[39m trees = [\n\u001B[32m    477\u001B[39m     \u001B[38;5;28mself\u001B[39m._make_estimator(append=\u001B[38;5;28;01mFalse\u001B[39;00m, random_state=random_state)\n\u001B[32m    478\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[32m    479\u001B[39m ]\n\u001B[32m    481\u001B[39m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[32m    482\u001B[39m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[32m    483\u001B[39m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[32m    484\u001B[39m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[32m    485\u001B[39m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[32m    486\u001B[39m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m487\u001B[39m trees = \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mthreads\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    501\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    502\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    503\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    504\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    505\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    506\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    508\u001B[39m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[32m    509\u001B[39m \u001B[38;5;28mself\u001B[39m.estimators_.extend(trees)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    137\u001B[39m     config = {}\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:189\u001B[39m, in \u001B[36m_parallel_build_trees\u001B[39m\u001B[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001B[39m\n\u001B[32m    186\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m class_weight == \u001B[33m\"\u001B[39m\u001B[33mbalanced_subsample\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    187\u001B[39m         curr_sample_weight *= compute_sample_weight(\u001B[33m\"\u001B[39m\u001B[33mbalanced\u001B[39m\u001B[33m\"\u001B[39m, y, indices=indices)\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m     \u001B[43mtree\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    190\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurr_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    196\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    197\u001B[39m     tree._fit(\n\u001B[32m    198\u001B[39m         X,\n\u001B[32m    199\u001B[39m         y,\n\u001B[32m   (...)\u001B[39m\u001B[32m    202\u001B[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001B[32m    203\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/ML_312/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001B[39m, in \u001B[36mBaseDecisionTree._fit\u001B[39m\u001B[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[39m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    462\u001B[39m     builder = BestFirstTreeBuilder(\n\u001B[32m    463\u001B[39m         splitter,\n\u001B[32m    464\u001B[39m         min_samples_split,\n\u001B[32m   (...)\u001B[39m\u001B[32m    469\u001B[39m         \u001B[38;5;28mself\u001B[39m.min_impurity_decrease,\n\u001B[32m    470\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m \u001B[43mbuilder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_outputs_ == \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    475\u001B[39m     \u001B[38;5;28mself\u001B[39m.n_classes_ = \u001B[38;5;28mself\u001B[39m.n_classes_[\u001B[32m0\u001B[39m]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Стремимся к\n",
    "- Все значения RMSE: [25419.11631511 23590.88424668 40286.11946863 26251.67462774\n",
    " 17518.97965098 25570.05300749 25002.81419282 20915.43518056\n",
    " 24727.88011941 31999.84374666 31155.31957707 21067.03441678\n",
    " 29403.32588714 18900.17080983 25119.71807368]\n",
    "- Средний RMSE на многократной кросс-валидации: 25795.2246\n",
    "- Стандартное отклонение RMSE: 5537.2770"
   ],
   "id": "263229a2c4ae4077"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Получили исходный результат выше, который хотим улучшить. Начинаем эксперименты.",
   "id": "4d32f2e5b5b1f5d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Пытаемся объединить фичи, которые явно не особо имеют смысла идти по отдельности, например: \n",
    "- BsmtFinSF1; BsmtFinSF2; BsmtUnfSF – кажется можно удалить и оставить только TotalBsmtSF\n",
    "- 1stFlrSF; 2ndFlrSF - кажется, можно заменить на сумму этих значений.\n",
    "\n",
    "Удаление площадей подвалов ничего не дало, кроме ухудшений.\n",
    "Добавление суммы с последующим удаление колонок - тоже ничего не дало.\n"
   ],
   "id": "660ce7bfbf252c4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Экспериментировал с регуляризацией catboost для уменьшения оверфиттинга - результат не изменился. Ниже испробованные конфигурации:\n",
    "params_1 = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'l2_leaf_reg': 3,\n",
    "    'rsm': 0.8,\n",
    "    'random_seed': RANDOM_STATE,\n",
    "    'verbose': 0\n",
    "}\n",
    "params_2 = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'l2_leaf_reg': 10,\n",
    "    'rsm': 0.8,\n",
    "    'random_seed': RANDOM_STATE,\n",
    "    'verbose': 0\n",
    "}\n",
    "params_4 = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 7,\n",
    "    'loss_function': 'RMSE',\n",
    "    'l2_leaf_reg': 5,\n",
    "    'rsm': 0.8,\n",
    "    'bagging_temperature': 1.0,\n",
    "    'random_strength': 1.5,\n",
    "    'random_seed': RANDOM_STATE,\n",
    "    'verbose': 0\n",
    "}\n",
    "params_5 = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'RMSE',\n",
    "    'l2_leaf_reg': 10,\n",
    "    'rsm': 0.8,\n",
    "    'bagging_temperature': 2.0,\n",
    "    'random_strength': 2.0,\n",
    "    'random_seed': RANDOM_STATE,\n",
    "    'verbose': 0\n",
    "}"
   ],
   "id": "bc48cff3b37daf0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Выше пробовали сгенерировать синтетическе данные - результат значительно (!) ухудшился на алгоритме synth_generator.\n",
    "На synth_generator_gaussian - результаты на малых синт. данных были схожими, но на больших - значительно хуже.\n",
    "CTGAN - не запустился."
   ],
   "id": "f80fbe7a651f605d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Добавление новых фич, без удаления старых - тоже не дало почти никакого улучшения. Только легкое ухудшение.",
   "id": "fa04564f91bfd9b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Нормализация y (log1p, sqrt, boxcox) - не дало улучшения.\n",
    "Удаление выбросов из всех данных - дало сильное улучшение, даже на cv, но на сабмишне - ухудшение. Оверфиттинг потому что получился."
   ],
   "id": "5852cb95641abc5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Получил небольшой прирост по RMSE, когда заменил onehot на target encoding и подобрал параметры энкодинга. По итогу вернулся к onehot  - он стабильнее.\n",
    "\n",
    "Еще улучшение небольшое при добавлении двух новых фичей в паре\n",
    "- X['Neighborhood_Zoning'] = X['Neighborhood'] + '_' + X['MSZoning']\n",
    "- X['SaleType_Condition'] = X['SaleType'] + '_' + X['SaleCondition']\n",
    "\n",
    "СУЩЕСТВЕННОЕ улучшение (400 по RMSE) при добавлении единого числового индекса по качественным призанкам\n",
    ">quality_dict = {'Ex': 5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.nan:0}\n",
    "\n",
    ">X['TotalQualScore'] = (\n",
    ">    X['ExterQual'].map(quality_dict) +\n",
    ">    X['KitchenQual'].map(quality_dict) +\n",
    ">    X['BsmtQual'].map(quality_dict) +\n",
    ">    X['HeatingQC'].map(quality_dict) +\n",
    ">    X['GarageQual'].map(quality_dict) +\n",
    ">    X['FireplaceQu'].map(quality_dict)\n",
    ">)\n"
   ],
   "id": "3e133c60dc5f4566"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ИТОГО: \n",
    "очень сильный прирост (почти +1к к RMSE) получили благодаря комбинации (!) новых признаков. И submission улучшился до 12877, что почти на 400 пунктов лучше прошлого сабмишна самого лучшего. Оставляем эти изменения. Все остальное - комментим.\n",
    "\n",
    "Небольшое улучшение от параметров вот таких: default_params = {\n",
    "    'iterations': 2000, \n",
    "    'learning_rate': 0.03, \n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 3,  # Можно варьировать (1, 3, 5, 7, 9)\n",
    "    'bagging_temperature': 1,\n",
    "    'loss_function': 'RMSE', \n",
    "    'verbose': 0, \n",
    "    'random_seed': RANDOM_STATE,\n",
    "    'early_stopping_rounds': 100,\n",
    "} добавили: 'l2_leaf_reg': 3, ; 'learning_rate': 0.03; 'iterations': 2000, НО на сабмишне хуже - поэтому откат.\n",
    "\n",
    "Добавление полиномиальных фич очень хорошо улучшило результаты (на тысячу + почти), но показатели на каггл плохие при самбишне - 13600, а было без полиномиальных 12877. На лицо, в очередной раз, оверфиттинг. Может, стоит поиграться параметром l2 регуляризации catboost?\n",
    "\n",
    "Винзоризация дает небольшое улучшение в +600 по RMSE, но при самбишне - ухудшение. Поэтому убираем.\n",
    "Winsorizing \"срезает\" хвосты распределения. Хотя это может помочь модели лучше подогнаться под основную массу данных в тренировочном наборе (уменьшая RMSE), эти экстремальные значения в тестовом наборе могут нести важную информацию. Возможно, очень большие дома (GrLivArea) или участки (LotArea) действительно имеют непропорционально высокую цену, и, ограничивая их значения сверху, мы заставляем модель недооценивать такие объекты в тесте.\n",
    "\n",
    "Пробовал возвращать удаленные интуитивно поля и экспериментировать с ними - ничего, кроме ухудшения не дало."
   ],
   "id": "5d40ed4a8a42f9fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Формируем Submission файл для Kaggle обучив модель на 100% данных",
   "id": "f372164a7e482af1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:49.831396Z",
     "start_time": "2025-04-01T20:43:16.435479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# final_pipeline.fit(X, y_log)\n",
    "# final_pipeline.fit(X, y_sqrt)\n",
    "final_pipeline.fit(X, y)"
   ],
   "id": "3f8d43a3cd1de60d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   IterativeImputer(estimator=RandomForestRegressor(n_estimators=50,\n",
       "                                                                                                                    random_state=42),\n",
       "                                                                                    random_state=42))]),\n",
       "                                                  Index(['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1',\n",
       "       'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF',\n",
       "       'EnclosedPorch', 'Fireplac...\n",
       "       'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC',\n",
       "       'HouseStyle', 'KitchenQual', 'MSZoning', 'MasVnrType', 'Neighborhood',\n",
       "       'Neighborhood_Zoning', 'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle',\n",
       "       'SaleCondition', 'SaleType', 'SaleType_Condition', 'Street',\n",
       "       'Utilities'],\n",
       "      dtype='object'))],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('model',\n",
       "                 <catboost.core.CatBoostRegressor object at 0x30e9ee870>)])"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   IterativeImputer(estimator=RandomForestRegressor(n_estimators=50,\n",
       "                                                                                                                    random_state=42),\n",
       "                                                                                    random_state=42))]),\n",
       "                                                  Index([&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;,\n",
       "       &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "       &#x27;EnclosedPorch&#x27;, &#x27;Fireplac...\n",
       "       &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HeatingQC&#x27;,\n",
       "       &#x27;HouseStyle&#x27;, &#x27;KitchenQual&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;Neighborhood&#x27;,\n",
       "       &#x27;Neighborhood_Zoning&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "       &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;SaleType_Condition&#x27;, &#x27;Street&#x27;,\n",
       "       &#x27;Utilities&#x27;],\n",
       "      dtype=&#x27;object&#x27;))],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 &lt;catboost.core.CatBoostRegressor object at 0x30e9ee870&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   IterativeImputer(estimator=RandomForestRegressor(n_estimators=50,\n",
       "                                                                                                                    random_state=42),\n",
       "                                                                                    random_state=42))]),\n",
       "                                                  Index([&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;,\n",
       "       &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "       &#x27;EnclosedPorch&#x27;, &#x27;Fireplac...\n",
       "       &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HeatingQC&#x27;,\n",
       "       &#x27;HouseStyle&#x27;, &#x27;KitchenQual&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;Neighborhood&#x27;,\n",
       "       &#x27;Neighborhood_Zoning&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "       &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;SaleType_Condition&#x27;, &#x27;Street&#x27;,\n",
       "       &#x27;Utilities&#x27;],\n",
       "      dtype=&#x27;object&#x27;))],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 &lt;catboost.core.CatBoostRegressor object at 0x30e9ee870&gt;)])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessing: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessing: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  IterativeImputer(estimator=RandomForestRegressor(n_estimators=50,\n",
       "                                                                                                   random_state=42),\n",
       "                                                                   random_state=42))]),\n",
       "                                 Index([&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;,\n",
       "       &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "       &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;, &#x27;GarageArea&#x27;, &#x27;Gara...\n",
       "       &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;Foundation&#x27;, &#x27;Functional&#x27;, &#x27;GarageCond&#x27;,\n",
       "       &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HeatingQC&#x27;,\n",
       "       &#x27;HouseStyle&#x27;, &#x27;KitchenQual&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;Neighborhood&#x27;,\n",
       "       &#x27;Neighborhood_Zoning&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "       &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;SaleType_Condition&#x27;, &#x27;Street&#x27;,\n",
       "       &#x27;Utilities&#x27;],\n",
       "      dtype=&#x27;object&#x27;))],\n",
       "                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;,\n",
       "       &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "       &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;, &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;,\n",
       "       &#x27;GarageYrBlt&#x27;, &#x27;GrLivArea&#x27;, &#x27;HalfBath&#x27;, &#x27;HasFence&#x27;, &#x27;HasFireplace&#x27;,\n",
       "       &#x27;HasGarage&#x27;, &#x27;HasPorchDeck&#x27;, &#x27;KitchenAbvGr&#x27;, &#x27;LotArea&#x27;, &#x27;LotFrontage&#x27;,\n",
       "       &#x27;LowQualFinSF&#x27;, &#x27;MSSubClass&#x27;, &#x27;MasVnrArea&#x27;, &#x27;MoSold&#x27;, &#x27;OpenPorchSF&#x27;,\n",
       "       &#x27;OverallCond&#x27;, &#x27;OverallQual&#x27;, &#x27;PoolArea&#x27;, &#x27;PorchDeckArea&#x27;,\n",
       "       &#x27;ScreenPorch&#x27;, &#x27;TotRmsAbvGrd&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;TotalQualScore&#x27;,\n",
       "       &#x27;WoodDeckSF&#x27;, &#x27;YearBuilt&#x27;, &#x27;YearRemodAdd&#x27;, &#x27;YrSold&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>imputer: IterativeImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.IterativeImputer.html\">?<span>Documentation for imputer: IterativeImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>IterativeImputer(estimator=RandomForestRegressor(n_estimators=50,\n",
       "                                                 random_state=42),\n",
       "                 random_state=42)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: RandomForestRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=50, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=50, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Index([&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;,\n",
       "       &#x27;BsmtFinType2&#x27;, &#x27;BsmtQual&#x27;, &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;, &#x27;Condition2&#x27;,\n",
       "       &#x27;Electrical&#x27;, &#x27;ExterCond&#x27;, &#x27;ExterQual&#x27;, &#x27;Exterior1st&#x27;, &#x27;Exterior2nd&#x27;,\n",
       "       &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;Foundation&#x27;, &#x27;Functional&#x27;, &#x27;GarageCond&#x27;,\n",
       "       &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HeatingQC&#x27;,\n",
       "       &#x27;HouseStyle&#x27;, &#x27;KitchenQual&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;Neighborhood&#x27;,\n",
       "       &#x27;Neighborhood_Zoning&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "       &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;SaleType_Condition&#x27;, &#x27;Street&#x27;,\n",
       "       &#x27;Utilities&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CatBoostRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x30e9ee870&gt;</pre></div> </div></div></div></div></div></div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:49.918416Z",
     "start_time": "2025-04-01T20:43:49.871216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_submission = test_data.drop(columns=bad_columns)\n",
    "X_submission.head()"
   ],
   "id": "d126df49bb5fb364",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley Utilities  \\\n",
       "0          20       RH         80.0    11622   Pave   NaN    AllPub   \n",
       "1          20       RL         81.0    14267   Pave   NaN    AllPub   \n",
       "2          60       RL         74.0    13830   Pave   NaN    AllPub   \n",
       "3          60       RL         78.0     9978   Pave   NaN    AllPub   \n",
       "4         120       RL         43.0     5005   Pave   NaN    AllPub   \n",
       "\n",
       "  Neighborhood Condition1 Condition2  ... EnclosedPorch 3SsnPorch  \\\n",
       "0        NAmes      Feedr       Norm  ...             0         0   \n",
       "1        NAmes       Norm       Norm  ...             0         0   \n",
       "2      Gilbert       Norm       Norm  ...             0         0   \n",
       "3      Gilbert       Norm       Norm  ...             0         0   \n",
       "4      StoneBr       Norm       Norm  ...             0         0   \n",
       "\n",
       "   ScreenPorch  PoolArea  PoolQC  Fence MoSold YrSold SaleType SaleCondition  \n",
       "0          120         0     NaN  MnPrv      6   2010       WD        Normal  \n",
       "1            0         0     NaN    NaN      6   2010       WD        Normal  \n",
       "2            0         0     NaN  MnPrv      3   2010       WD        Normal  \n",
       "3            0         0     NaN    NaN      6   2010       WD        Normal  \n",
       "4          144         0     NaN    NaN      1   2010       WD        Normal  \n",
       "\n",
       "[5 rows x 73 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>StoneBr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:50.027255Z",
     "start_time": "2025-04-01T20:43:49.996574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Делаем теже преобразования с X_submission, что и с X\n",
    "# X_submission['TotalSF'] = X_submission['1stFlrSF'] + X_submission['2ndFlrSF'] + X_submission['TotalBsmtSF']\n",
    "# X_submission['Age'] = X_submission['YrSold'] - X_submission['YearBuilt']\n",
    "# X_submission['QualityIndex'] = X_submission['OverallQual'] * X_submission['OverallCond']\n",
    "# X_submission['HasPool'] = (X_submission['PoolArea'] > 0).astype(int)\n",
    "# X_submission['Remodeled'] = (X_submission['YearRemodAdd'] != X_submission['YearBuilt']).astype(int)\n",
    "# X_submission['TotalBathrooms'] = X_submission['FullBath'] + 0.5 * X_submission['HalfBath'] + X_submission['BsmtFullBath'] + 0.5 * X_submission['BsmtHalfBath']\n",
    "# X_submission.shape\n",
    "\n",
    "X_submission['Neighborhood_Zoning'] = X_submission['Neighborhood'] + '_' + X_submission['MSZoning']\n",
    "X_submission['SaleType_Condition'] = X_submission['SaleType'] + '_' + X_submission['SaleCondition']\n",
    "X_submission['TotalQualScore'] = (\n",
    "    X_submission['ExterQual'].map(quality_dict) +\n",
    "    X_submission['KitchenQual'].map(quality_dict) +\n",
    "    X_submission['BsmtQual'].map(quality_dict) +\n",
    "    X_submission['HeatingQC'].map(quality_dict) +\n",
    "    X_submission['GarageQual'].map(quality_dict) +\n",
    "    X_submission['FireplaceQu'].map(quality_dict)\n",
    ")\n",
    "X_submission['PorchDeckArea'] = (X_submission['WoodDeckSF'] + X_submission['OpenPorchSF'] + X_submission['EnclosedPorch'] +\n",
    "                      X_submission['3SsnPorch'] + X_submission['ScreenPorch'])\n",
    "X_submission['HasFireplace'] = (X_submission['Fireplaces'] > 0).astype(int)\n",
    "X_submission['HasGarage'] = (~X_submission['GarageType'].isna()).astype(int)\n",
    "X_submission['HasFence'] = (~X_submission['Fence'].isna()).astype(int)\n",
    "X_submission['HasPorchDeck'] = (X_submission['PorchDeckArea'] > 0).astype(int)\n",
    "X_submission.shape"
   ],
   "id": "b9e041a2daf5d6dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 81)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:50.087006Z",
     "start_time": "2025-04-01T20:43:50.058737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ОЧЕНЬ ВАЖНО убедиться, что набор признаков (X_submission) абсолютно совпадает с X по количеству и порядку колонок!\n",
    "# Приводим колонки точно к нужному порядку:\n",
    "X_submission = X_submission.reindex(columns=feature_cols)"
   ],
   "id": "3266ff3e24747cba",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:50.210251Z",
     "start_time": "2025-04-01T20:43:50.109867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_submission = final_pipeline.predict(X_submission)\n",
    "y_submission"
   ],
   "id": "333b60d9c15c4c87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121982.72314189, 157490.60448354, 189784.29652449, ...,\n",
       "       165699.65513501, 117650.3575256 , 223710.15453793])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:50.285050Z",
     "start_time": "2025-04-01T20:43:50.261720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обратное преобразование для возврата к исходной шкале\n",
    "# y_submission = np.expm1(y_submission)\n",
    "# y_submission = y_submission ** 2\n",
    "# y_submission"
   ],
   "id": "c002d0f955ff636f",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:50.366508Z",
     "start_time": "2025-04-01T20:43:50.338124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'],\n",
    "    'SalePrice': y_submission\n",
    "})\n",
    "submission.set_index('Id', inplace=True)\n",
    "submission.head()"
   ],
   "id": "5c26e53beea63474",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          SalePrice\n",
       "Id                 \n",
       "1461  121982.723142\n",
       "1462  157490.604484\n",
       "1463  189784.296524\n",
       "1464  192438.774384\n",
       "1465  176565.159645"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>121982.723142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>157490.604484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>189784.296524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>192438.774384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>176565.159645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:43:50.459557Z",
     "start_time": "2025-04-01T20:43:50.432193Z"
    }
   },
   "cell_type": "code",
   "source": "submission.to_csv('submission_final_with_new_features_v4.7.csv')",
   "id": "4b32dc8843b68a47",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c0ce152934e0996"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
