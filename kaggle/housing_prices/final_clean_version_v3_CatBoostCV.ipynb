{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Реализация CatBoostCV",
   "id": "342e465227f21e61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.308814Z",
     "start_time": "2025-04-06T20:35:19.230162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Вместо одного фиксированного разбиения на train/test используем стабильную стратегию кросс-валидации.\n",
    "# Используем тут Cross-validation, потому что:\n",
    "# \t•\tнужно надёжно сравнить несколько разных моделей или гиперпараметров и понять, какая модель стабильнее и лучше в целом.\n",
    "# \t•\tхотим избежать случайных удач или провалов, связанных с конкретным разбиением на train/test.\n",
    "# \t•\tвыбираем модель или гиперпараметры, которые потом будешь использовать для финального сабмишна на Kaggle.\n",
    "# Делаем эту оценку, чтобы в дальнейших блокнотах-улучшениях сравнивать более корректно.\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score, train_test_split\n",
    "\n",
    "# Используем IterativeImputer:\n",
    "# \t•\tОн итеративно заполняет все пропуски сразу.\n",
    "# \t•\tРаботает одновременно со всеми признаками, учитывая связи между ними.\n",
    "# \t•\tНе требует ручного управления порядком заполнения.\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from utils.data_manager import DataManager\n",
    "from utils.model_manager import ModelManager\n",
    "from utils.syth_generator_gaussian import CombinedSyntheticGenerator"
   ],
   "id": "420e4ab0c758878b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.347531Z",
     "start_time": "2025-04-06T20:35:19.319202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Глобально включаем вывод Pandas для всех трансформеров ---\n",
    "# (Можно применять и к отдельным трансформерам/пайплайнам .set_output(transform=\"pandas\"))\n",
    "set_config(transform_output = \"pandas\")"
   ],
   "id": "199739c5b006ce85",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.405840Z",
     "start_time": "2025-04-06T20:35:19.377457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dm = DataManager()\n",
    "mm = ModelManager()\n",
    "\n",
    "# Отключаем автологгирование, чтобы использовать ручное\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "warnings.filterwarnings(\"ignore\", module=\"mlflow\")  # Игнорируем предупреждения MLflow\n"
   ],
   "id": "46cfc863ccd450e3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.460940Z",
     "start_time": "2025-04-06T20:35:19.433044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5  # Например, 5 или 10"
   ],
   "id": "1d255490f031f964",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Загрузка данных",
   "id": "55984fe689a63884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.532676Z",
     "start_time": "2025-04-06T20:35:19.486824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = 'data/home-data-for-ml-course'\n",
    "train_data = pd.read_csv(data_path + '/train.csv')\n",
    "test_data = pd.read_csv(data_path + '/test.csv')\n",
    "train_data.shape"
   ],
   "id": "7d598e3cbc36cac0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Предобработка данных ",
   "id": "6940432e3f3f4b41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.593218Z",
     "start_time": "2025-04-06T20:35:19.561624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Определение колонок для удаления\n",
    "intuitively_bad_features = [\n",
    "    'LotShape',  # Общая форма участка\n",
    "    'LandContour',  # Рельеф участка\n",
    "    'LotConfig',  # Конфигурация участка\n",
    "    'LandSlope',  # Уклон участка\n",
    "    'MiscFeature',\n",
    "    'MiscVal',\n",
    "]\n",
    "bad_columns = dm.get_all_nan_cols(train_data)\n",
    "bad_columns.append('Id')\n",
    "bad_columns.extend(intuitively_bad_features)"
   ],
   "id": "1c983295e743bf49",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.649432Z",
     "start_time": "2025-04-06T20:35:19.619234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Разделение на X / y\n",
    "X, y = dm.split_data_set_to_x_y(train_data, 'SalePrice')\n",
    "print(X.shape, y.shape)\n",
    "X_test = test_data.copy()\n",
    "print(X_test.shape)"
   ],
   "id": "804670ecec700911",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80) (1460,)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.704773Z",
     "start_time": "2025-04-06T20:35:19.675872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X.drop(columns=bad_columns, inplace=True)\n",
    "X_test.drop(columns=bad_columns, inplace=True)"
   ],
   "id": "6634727d1e06cd4c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.769738Z",
     "start_time": "2025-04-06T20:35:19.736832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_feature_eng_great_again(train_X_in, test_X_in):\n",
    "    \"\"\"Хелпер, который создает фичи, логарифмирует и выравнивает колонки.\"\"\"\n",
    "    # Работаем с копиями, чтобы не изменять оригинальные X, X_test вне функции\n",
    "    train_X = train_X_in.copy()\n",
    "    test_X = test_X_in.copy()\n",
    "\n",
    "    # Словарь качественных признаков\n",
    "    quality_dict = {'Ex': 5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.nan:0}\n",
    "\n",
    "    def create_features(df):\n",
    "        # Interactions (с проверкой на наличие колонок)\n",
    "        if 'Neighborhood' in df.columns and 'MSZoning' in df.columns:\n",
    "            df['Neighborhood_Zoning'] = df['Neighborhood'].astype(str) + '_' + df['MSZoning'].astype(str)\n",
    "            # df.drop(columns=['Neighborhood', 'MSZoning'], inplace=True)  # mean CV RMSLE улучшился на 0.008, oof rmse улучшился на 0.0011; KAGGLE LB УПАЛ!!!\n",
    "        if 'SaleType' in df.columns and 'SaleCondition' in df.columns:\n",
    "            df['SaleType_Condition'] = df['SaleType'].astype(str) + '_' + df['SaleCondition'].astype(str)\n",
    "            # df.drop(columns=['SaleType', 'SaleCondition'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        # Quality Score\n",
    "        df['TotalQualScore'] = 0\n",
    "        quality_cols = ['ExterQual', 'KitchenQual', 'BsmtQual', 'HeatingQC', 'GarageQual', 'FireplaceQu']\n",
    "        for col in quality_cols:\n",
    "            if col in df.columns:\n",
    "                 df['TotalQualScore'] += df[col].map(quality_dict).fillna(0)\n",
    "        # df.drop(columns=quality_cols, inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        # Porch/Deck Area and Flags\n",
    "        df['PorchDeckArea'] = 0\n",
    "        porch_cols = ['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n",
    "        for col in porch_cols:\n",
    "             if col in df.columns:\n",
    "                df['PorchDeckArea'] += df[col].fillna(0)\n",
    "        # df.drop(columns=porch_cols, inplace=True)  # Mean CV RMSE улучшился на 0.0008, oof rmse улучшился на 0.0006; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        if 'Fireplaces' in df.columns:\n",
    "            df['HasFireplace'] = (df['Fireplaces'] > 0).astype(int)\n",
    "            # df.drop(columns=['Fireplaces'], inplace=True)  # !!! mean cv rmse улучшился на 0.0023, oof rmse улучшился на 0.0031. fold 3 проблемный очень хорошо улучшился без этой фичи; KAGGLE LB УПАЛ!!!\n",
    "        if 'GarageType' in df.columns:\n",
    "            df['HasGarage'] = (~df['GarageType'].isna()).astype(int)\n",
    "            # df.drop(columns=['GarageType'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "        if 'Fence' in df.columns:\n",
    "            df['HasFence'] = (~df['Fence'].isna()).astype(int)\n",
    "            # df.drop(columns=['Fence'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "        df['HasPorchDeck'] = (df['PorchDeckArea'] > 0).astype(int)\n",
    "        # df.drop(columns=['PorchDeckArea'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        return df\n",
    "\n",
    "    def log_features(df, cols_to_log_list):  # Принимает СПИСОК колонок\n",
    "        print(f\"Applying log1p to: {cols_to_log_list}\")\n",
    "        for col_name in cols_to_log_list:\n",
    "            if col_name in df.columns:\n",
    "                # Добавим проверку на отрицательные значения перед логарифмированием\n",
    "                if (df[col_name] < 0).any():\n",
    "                     print(f\"Warning: Column {col_name} contains negative values. Skipping log1p.\")\n",
    "                else:\n",
    "                    df[col_name] = np.log1p(df[col_name])\n",
    "            else:\n",
    "                print(f\"Warning: Column {col_name} not found in DF during log transform.\")\n",
    "        return df\n",
    "\n",
    "    # 1. Создаем фичи\n",
    "    train_X = create_features(train_X)\n",
    "    test_X = create_features(test_X)\n",
    "    print(\"Features created.\")\n",
    "\n",
    "    # 2. Определяем колонки для логарифмирования (ТОЛЬКО по трейну)\n",
    "    numeric_cols = train_X.select_dtypes(include=np.number).columns\n",
    "    skew_values = train_X[numeric_cols].skew()\n",
    "    # Используем .index.tolist() чтобы получить список имен\n",
    "    cols_to_log_list = skew_values[skew_values > 1].index.tolist()\n",
    "    print(f\"Columns identified for logging: {cols_to_log_list}\")\n",
    "\n",
    "    # # 3. Логарифмируем (используя ОДИН и тот же список)\n",
    "    # train_X = log_features(train_X, cols_to_log_list)\n",
    "    # test_X = log_features(test_X, cols_to_log_list)\n",
    "    # print(\"Log transform applied.\")\n",
    "\n",
    "    # 4. Согласуем и сортируем колонки ПОСЛЕ всех манипуляций\n",
    "    final_feature_cols = sorted(train_X.columns.tolist()) # Сортируем для стабильности\n",
    "    train_X = train_X[final_feature_cols]\n",
    "    test_X = test_X.reindex(columns=final_feature_cols, fill_value=0)\n",
    "    print(\"Columns aligned and sorted.\")\n",
    "\n",
    "    return train_X, test_X"
   ],
   "id": "f602aa5cb0e7fbed",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.835921Z",
     "start_time": "2025-04-06T20:35:19.795811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Вызываем функцию с правильными данными (X, X_test)\n",
    "X, X_test = make_feature_eng_great_again(X, X_test)\n",
    "\n",
    "print(\"\\nProcessing complete. Final shapes:\")\n",
    "print(f\"X_processed: {X.shape}\")\n",
    "print(f\"X_test_processed: {X_test.shape}\")\n",
    "print(\"\\nExample processed X:\")\n",
    "print(X.head())"
   ],
   "id": "88f29b4b07dd06fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created.\n",
      "Columns identified for logging: ['MSSubClass', 'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtHalfBath', 'KitchenAbvGr', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PorchDeckArea', 'HasFence']\n",
      "Columns aligned and sorted.\n",
      "\n",
      "Processing complete. Final shapes:\n",
      "X_processed: (1460, 81)\n",
      "X_test_processed: (1459, 81)\n",
      "\n",
      "Example processed X:\n",
      "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
      "0       856       854          0   NaN             3     1Fam       TA   \n",
      "1      1262         0          0   NaN             3     1Fam       TA   \n",
      "2       920       866          0   NaN             3     1Fam       TA   \n",
      "3       961       756          0   NaN             3     1Fam       Gd   \n",
      "4      1145      1053          0   NaN             4     1Fam       TA   \n",
      "\n",
      "  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ... ScreenPorch Street  TotRmsAbvGrd  \\\n",
      "0           No         706           0  ...           0   Pave             8   \n",
      "1           Gd         978           0  ...           0   Pave             6   \n",
      "2           Mn         486           0  ...           0   Pave             6   \n",
      "3           No         216           0  ...           0   Pave             7   \n",
      "4           Av         655           0  ...           0   Pave             9   \n",
      "\n",
      "   TotalBsmtSF TotalQualScore  Utilities WoodDeckSF YearBuilt YearRemodAdd  \\\n",
      "0          856             20     AllPub          0      2003         2003   \n",
      "1         1262             21     AllPub        298      1976         1976   \n",
      "2          920             23     AllPub          0      2001         2002   \n",
      "3          756             21     AllPub          0      1915         1970   \n",
      "4         1145             23     AllPub        192      2000         2000   \n",
      "\n",
      "  YrSold  \n",
      "0   2008  \n",
      "1   2007  \n",
      "2   2008  \n",
      "3   2006  \n",
      "4   2008  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:35:19.892751Z",
     "start_time": "2025-04-06T20:35:19.862748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Получение числовых колонок\n",
    "numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "# Получение нечисловых колонок (всех остальных)\n",
    "non_numeric_columns = X.select_dtypes(exclude=['float64', 'int64']).columns"
   ],
   "id": "4f3cc3b95d48e36d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Обучаем модель с CV и корректируя данные",
   "id": "1351be3fe2eee231"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:04:53.282576Z",
     "start_time": "2025-04-06T21:04:53.213874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    # ('scaler', StandardScaler())  # разницы не дает \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# --- Объединяем препроцессоры ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Применяем к исходным числовым колонкам\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        # Применяем к исходным категориальным колонкам\n",
    "        ('cat', categorical_transformer, non_numeric_columns)\n",
    "    ],\n",
    "    remainder='drop',   # 'passthrough' сохранит полиномиальные и другие колонки, которые не были ни числовыми, ни категориальными ИЗНАЧАЛЬНО\n",
    "    verbose_feature_names_out=False  # Чтобы имена колонок не менялись на 'num__colname' и т.д.\n",
    ")\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "X_test = preprocessor.transform(X_test)"
   ],
   "id": "9a43119bf6727b6f",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:56:13.715079Z",
     "start_time": "2025-04-06T20:56:13.652709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_cv_summary(cv_data):\n",
    "    print(\"CV Results DataFrame Head:\")\n",
    "    print(cv_data.head()) # Печатаем начало таблицы для проверки имен колонок\n",
    "    print(\"\\nAvailable columns:\", cv_data.columns.tolist()) # Печатаем все имена колонок\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # --- ИСПРАВЛЕНИЕ ---\n",
    "    # Используем имена колонок для RMSE, т.к. loss_function='RMSE'\n",
    "    metric_mean_col = 'test-RMSE-mean'\n",
    "    metric_std_col = 'test-RMSE-std'\n",
    "\n",
    "    # Проверка на случай, если колонки все же не создались (маловероятно, но надежнее)\n",
    "    if metric_mean_col not in cv_data.columns:\n",
    "        print(f\"ОШИБКА: Колонка '{metric_mean_col}' не найдена в результатах CV!\")\n",
    "        return # Выходим из функции, если нет нужной колонки\n",
    "\n",
    "    best_value = cv_data[metric_mean_col].min()\n",
    "    # Используем idxmin() для pandas Series - надежнее, чем argmin()\n",
    "    best_iter = cv_data[metric_mean_col].idxmin()\n",
    "\n",
    "    # Получаем стандартное отклонение, проверяя наличие колонки\n",
    "    std_value = 0.0 # Значение по умолчанию, если колонка std отсутствует\n",
    "    if metric_std_col in cv_data.columns:\n",
    "         # Доступ по индексу best_iter, который вернул idxmin()\n",
    "        std_value = cv_data[metric_std_col][best_iter]\n",
    "    else:\n",
    "        print(f\"Предупреждение: Колонка '{metric_std_col}' не найдена. Std будет 0.\")\n",
    "\n",
    "\n",
    "    print('Best validation RMSE score : {:.4f} ± {:.4f} on step {}'.format(\n",
    "        best_value,\n",
    "        std_value, # Используем полученное или дефолтное значение std\n",
    "        best_iter)\n",
    "    )"
   ],
   "id": "351983bb07567469",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:04:53.198640Z",
     "start_time": "2025-04-06T21:03:50.051692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from catboost import  cv, Pool\n",
    "\n",
    "# --- Логарифмирование целевой переменной ---\n",
    "y_log = np.log1p(y)  # Т.к. нет RMSLE потери у loss_function catboost.cv\n",
    "\n",
    "train_pool = Pool(data=X, \n",
    "                  label=y_log,\n",
    "                  cat_features=non_numeric_columns.values, \n",
    "                  has_header=True\n",
    "                  )\n",
    "\n",
    "# parameters for training inside cv:\n",
    "params = {\n",
    "    'iterations': 1000, \n",
    "    'learning_rate': 0.05, \n",
    "    'depth': 6, \n",
    "    'loss_function': 'RMSE', \n",
    "}\n",
    "\n",
    "cv_data = cv(\n",
    "    params=params,\n",
    "    pool=train_pool,\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=False,\n",
    "    stratified=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print_cv_summary(cv_data)"
   ],
   "id": "18bfb61c6c644b3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.1883383887\n",
      "bestIteration = 994\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.191445652\n",
      "bestIteration = 996\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.1831752595\n",
      "bestIteration = 994\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.1853328536\n",
      "bestIteration = 998\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.1615958298\n",
      "bestIteration = 997\n",
      "\n",
      "CV Results DataFrame Head:\n",
      "   iterations  test-RMSE-mean  test-RMSE-std  train-RMSE-mean  train-RMSE-std\n",
      "0           0       11.449492       0.016265        11.447650        0.008519\n",
      "1           1       10.897370       0.024148        10.896375        0.017496\n",
      "2           2       10.375870       0.032902        10.373011        0.019943\n",
      "3           3        9.874257       0.032008         9.870556        0.023149\n",
      "4           4        9.396932       0.030249         9.396275        0.023939\n",
      "\n",
      "Available columns: ['iterations', 'test-RMSE-mean', 'test-RMSE-std', 'train-RMSE-mean', 'train-RMSE-std']\n",
      "\n",
      "\n",
      "Best validation RMSE score : 0.1820 ± 0.0118 on step 996\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:07:49.087628Z",
     "start_time": "2025-04-06T21:07:40.082972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Получаем оптимальное количество итераций из результатов CV\n",
    "metric_mean_col = 'test-RMSE-mean'\n",
    "if metric_mean_col in cv_data.columns:\n",
    "    best_iter_idx = cv_data[metric_mean_col].idxmin()\n",
    "    optimal_iterations = best_iter_idx + 1\n",
    "    print(f\"\\nОптимальное количество итераций по результатам CV: {optimal_iterations}\")\n",
    "else:\n",
    "    print(f\"Не удалось найти колонку {metric_mean_col} в cv_data. Используем дефолтное количество итераций.\")\n",
    "    optimal_iterations = params.get('iterations', 1000) # Берем из исходных params\n",
    "\n",
    "# 2. Определяем параметры для финальной модели\n",
    "final_params = params.copy()\n",
    "final_params['iterations'] = optimal_iterations\n",
    "final_params['random_seed'] = RANDOM_STATE\n",
    "# Убери custom_loss если он был в params\n",
    "if 'custom_loss' in final_params: del final_params['custom_loss']\n",
    "\n",
    "print(\"\\nПараметры для финальной модели:\")\n",
    "print(final_params)\n",
    "\n",
    "# 3. Инициализируем и обучаем финальную модель\n",
    "final_model = CatBoostRegressor(**final_params)\n",
    "\n",
    "print(\"\\nОбучение финальной модели на всем train_pool...\")\n",
    "# Обучаем на том же train_pool (который содержит X и y_log)\n",
    "final_model.fit(train_pool, verbose=100)\n",
    "print(\"Обучение завершено.\")\n",
    "\n",
    "# 4. Делаем предсказания на тестовых данных (X_test)\n",
    "#    Убедись, что X_test прошел ТОЧНО ТАКУЮ ЖЕ обработку NaN в категориальных колонках, как X\n",
    "print(\"\\nСоздание предсказаний для X_test...\")\n",
    "predictions_log = final_model.predict(X_test) # Предсказания будут в лог. масштабе\n",
    "print(\"Предсказания (в лог. масштабе) созданы.\")\n",
    "\n",
    "# 5. Пост-обработка предсказаний: ОБРАТНОЕ ПРЕОБРАЗОВАНИЕ (ОБЯЗАТЕЛЬНО!)\n",
    "print(\"Применение обратного преобразования np.expm1() к предсказаниям...\")\n",
    "predictions = np.expm1(predictions_log) # <--- Вот этот шаг теперь обязателен!\n",
    "print(\"Обратное преобразование завершено.\")\n",
    "\n",
    "# Проверка на отрицательные значения (цены не могут быть отрицательными)\n",
    "predictions[predictions < 0] = 0 # Заменяем возможные отриц. значения на 0\n",
    "\n",
    "# 6. Создание файла для сабмишна\n",
    "print(\"\\nФормирование файла для сабмишна...\")\n",
    "# Убедись, что test_data - это исходный файл test.csv, загруженный в начале\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'],\n",
    "    'SalePrice': predictions\n",
    "})\n",
    "\n",
    "# Сохраняем файл\n",
    "submission_file = 'final_submission_Clean_catboost_cv_log_v1.csv'\n",
    "submission.to_csv(submission_file, index=False)\n",
    "print(f\"Файл для сабмишна сохранен как: {submission_file}\")\n",
    "print(submission.head())\n",
    "\n"
   ],
   "id": "57e1425f26584a5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Оптимальное количество итераций по результатам CV: 997\n",
      "\n",
      "Параметры для финальной модели:\n",
      "{'iterations': 997, 'learning_rate': 0.05, 'depth': 6, 'loss_function': 'RMSE', 'random_seed': 42}\n",
      "\n",
      "Обучение финальной модели на всем train_pool...\n",
      "0:\tlearn: 0.3855520\ttotal: 17.7ms\tremaining: 17.6s\n",
      "100:\tlearn: 0.1126572\ttotal: 956ms\tremaining: 8.48s\n",
      "200:\tlearn: 0.0950676\ttotal: 1.83s\tremaining: 7.24s\n",
      "300:\tlearn: 0.0862630\ttotal: 2.87s\tremaining: 6.65s\n",
      "400:\tlearn: 0.0794245\ttotal: 3.78s\tremaining: 5.62s\n",
      "500:\tlearn: 0.0718999\ttotal: 4.65s\tremaining: 4.61s\n",
      "600:\tlearn: 0.0665271\ttotal: 5.41s\tremaining: 3.56s\n",
      "700:\tlearn: 0.0611366\ttotal: 6.28s\tremaining: 2.65s\n",
      "800:\tlearn: 0.0562032\ttotal: 7.08s\tremaining: 1.73s\n",
      "900:\tlearn: 0.0520739\ttotal: 8.03s\tremaining: 855ms\n",
      "996:\tlearn: 0.0488397\ttotal: 8.79s\tremaining: 0us\n",
      "Обучение завершено.\n",
      "\n",
      "Создание предсказаний для X_test...\n",
      "Предсказания (в лог. масштабе) созданы.\n",
      "Применение обратного преобразования np.expm1() к предсказаниям...\n",
      "Обратное преобразование завершено.\n",
      "\n",
      "Формирование файла для сабмишна...\n",
      "Файл для сабмишна сохранен как: final_submission_Clean_catboost_cv_log_v1.csv\n",
      "     Id      SalePrice\n",
      "0  1461  120680.870195\n",
      "1  1462  159001.405593\n",
      "2  1463  184874.642947\n",
      "3  1464  197396.781075\n",
      "4  1465  182791.638775\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ИТОГО\n",
    "Никакой магии, дефолтный cv катбуста дал такие же показатели."
   ],
   "id": "f2e763cdaf20dfe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c4178cf54caab008"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
