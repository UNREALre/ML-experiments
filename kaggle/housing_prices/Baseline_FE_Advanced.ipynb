{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# KFold + Catboost Baseline + Advanced Feature Engineering\n",
    "Накручиваем поверх Baseline продвинутое FE."
   ],
   "id": "29102a4f1e062b26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.712884Z",
     "start_time": "2025-04-14T16:33:57.168742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "# Вместо одного фиксированного разбиения на train/test используем стабильную стратегию кросс-валидации.\n",
    "# Используем тут Cross-validation, потому что:\n",
    "# \t•\tнужно надёжно сравнить несколько разных моделей или гиперпараметров и понять, какая модель стабильнее и лучше в целом.\n",
    "# \t•\tхотим избежать случайных удач или провалов, связанных с конкретным разбиением на train/test.\n",
    "# \t•\tвыбираем модель или гиперпараметры, которые потом будешь использовать для финального сабмишна на Kaggle.\n",
    "# Делаем эту оценку, чтобы в дальнейших блокнотах-улучшениях сравнивать более корректно.\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score, train_test_split\n",
    "\n",
    "# Используем IterativeImputer:\n",
    "# \t•\tОн итеративно заполняет все пропуски сразу.\n",
    "# \t•\tРаботает одновременно со всеми признаками, учитывая связи между ними.\n",
    "# \t•\tНе требует ручного управления порядком заполнения.\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from utils.data_manager import DataManager, CrossFoldEncoder\n",
    "from utils.model_manager import ModelManager\n",
    "from utils.syth_generator_gaussian import CombinedSyntheticGenerator\n",
    "\n",
    "\n",
    "# Зависимости для FE\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ],
   "id": "d815cc32b92f72fe",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.743706Z",
     "start_time": "2025-04-14T16:33:59.716032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Глобально включаем вывод Pandas для всех трансформеров ---\n",
    "# (Можно применять и к отдельным трансформерам/пайплайнам .set_output(transform=\"pandas\"))\n",
    "set_config(transform_output = \"pandas\")"
   ],
   "id": "cbe9224fd4e2b5dc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.853507Z",
     "start_time": "2025-04-14T16:33:59.829423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dm = DataManager()\n",
    "mm = ModelManager()\n",
    "\n",
    "# Отключаем автологгирование, чтобы использовать ручное\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "warnings.filterwarnings(\"ignore\", module=\"mlflow\")  # Игнорируем предупреждения MLflow\n"
   ],
   "id": "7228dc2937707f33",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.881117Z",
     "start_time": "2025-04-14T16:33:59.859770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5  # Например, 5 или 10"
   ],
   "id": "a3e055dca20f3884",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.904254Z",
     "start_time": "2025-04-14T16:33:59.885497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Корреляционная матрица дата-сета\n",
    "# dm.corrplot(train_data, annot=None)"
   ],
   "id": "62c49d845861f9e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Предобработка данных ",
   "id": "7b2a25badd3fdad2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.927191Z",
     "start_time": "2025-04-14T16:33:59.908368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A label encoding is okay for any kind of categorical feature when you're using a tree-ensemble like XGBoost, even for unordered categories. If you wanted to try a linear regression model (also popular in this competition), you would instead want to use a one-hot encoding, especially for the features with unordered categories.\n",
    "# X_prep = dm.label_encode(X_prep)"
   ],
   "id": "4589032d18226d83",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.948071Z",
     "start_time": "2025-04-14T16:33:59.930995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # OHE по факту\n",
    "# print(X_prep.BldgType.unique())\n",
    "# tmp_df = pd.get_dummies(X_prep.BldgType, prefix=\"Bldg\")\n",
    "# tmp_df"
   ],
   "id": "8cac286eba9758ef",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:23:53.393698Z",
     "start_time": "2025-04-14T18:23:53.329321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Базовые фичи, получаемы манипуляцией с данными\n",
    "def mathematical_transforms(df):\n",
    "    X = pd.DataFrame()  # dataframe to hold new features\n",
    "    X[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n",
    "    X[\"Spaciousness\"] = (df['1stFlrSF'] + df['2ndFlrSF']) / df.TotRmsAbvGrd\n",
    "    return X\n",
    "\n",
    "def interactions(df):\n",
    "    # Получим новые признаки, которые сочетают в себе категориальную и числовую информацию. Модель сможет учитывать \n",
    "    # не просто тип здания, но и то, как конкретный тип здания влияет на значение площади и, соответственно, на целевую переменную.\n",
    "    # Создаем бинарные признаки для каждого уникального типа здания:\n",
    "    X = pd.get_dummies(df.BldgType, prefix=\"Bldg\")  # Тип жилого здания\n",
    "    # Каждый бинарный признак умножается на площадь здания\n",
    "    X = X.mul(df.GrLivArea, axis=0)  # Жилая площадь над уровнем земли\n",
    "\n",
    "    # Район в пределах города + общая классификация зонирования продажи\n",
    "    X['Neighborhood_Zoning'] = df['Neighborhood'].astype(str) + '_' + df['MSZoning'].astype(str)\n",
    "\n",
    "    # Тип продажи + Условия продажи\n",
    "    X['SaleType_Condition'] = df['SaleType'].astype(str) + '_' + df['SaleCondition'].astype(str)\n",
    "\n",
    "    quality_dict = {'Ex': 5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.nan:0}  # Словарь качественных признаков\n",
    "    X['TotalQualScore'] = 0\n",
    "    # Качество внешней отделки; Качество кухни; Высота подвала; Качество и состояние отопления; Качество гаража;\n",
    "    # Качество камина\n",
    "    quality_cols = ['ExterQual', 'KitchenQual', 'BsmtQual', 'HeatingQC', 'GarageQual', 'FireplaceQu']\n",
    "    for col in quality_cols:\n",
    "        if col in df.columns:\n",
    "             X['TotalQualScore'] += df[col].map(quality_dict).fillna(0)\n",
    "\n",
    "    X['PorchDeckArea'] = 0\n",
    "    # Площадь деревянной террасы; Площадь открытой террасы; Площадь закрытой террасы; Площадь 3-сезонной террасы; Площадь экрана\n",
    "    porch_cols = ['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n",
    "    for col in porch_cols:\n",
    "         if col in df.columns:\n",
    "            X['PorchDeckArea'] += df[col].fillna(0)\n",
    "    X['HasPorchDeck'] = (X['PorchDeckArea'] > 0).astype(int)\n",
    "\n",
    "    # Количество каминов\n",
    "    X['HasFireplace'] = (df['Fireplaces'] > 0).astype(int)\n",
    "\n",
    "    # Тип гаража\n",
    "    X['HasGarage'] = (~df['GarageType'].isna()).astype(int)\n",
    "\n",
    "    # Качество забора\n",
    "    X['HasFence'] = (~df['Fence'].isna()).astype(int)\n",
    "\n",
    "    return X\n",
    "\n",
    "def counts(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"PorchTypes\"] = df[[\n",
    "        \"WoodDeckSF\",\n",
    "        \"OpenPorchSF\",\n",
    "        \"EnclosedPorch\",\n",
    "        \"3SsnPorch\",\n",
    "        \"ScreenPorch\",\n",
    "    ]].gt(0.0).sum(axis=1)\n",
    "    return X\n",
    "\n",
    "def break_down(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"MSClass\"] = df.MSSubClass.str.split(\"_\", n=1, expand=True)[0]\n",
    "    return X\n",
    "\n",
    "def group_transforms(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n",
    "    return X"
   ],
   "id": "69b75a516bc4c556",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:33:59.997623Z",
     "start_time": "2025-04-14T16:33:59.975946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# K-Means\n",
    "cluster_features = [\n",
    "    \"LotArea\",  # Площадь участка в квадратных футах\n",
    "    \"TotalBsmtSF\",  # Общая площадь подвала\n",
    "    \"1stFlrSF\",  # Площадь первого этажа\n",
    "    \"2ndFlrSF\",  # Площадь второго этажа\n",
    "    \"GrLivArea\",  # Жилая площадь над уровнем земли\n",
    "]\n",
    "\n",
    "\n",
    "def cluster_labels(df, features, n_clusters=20):\n",
    "    X = df.copy()\n",
    "    X_scaled = X.loc[:, features]\n",
    "    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n",
    "    X_new = pd.DataFrame()\n",
    "    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "def cluster_distance(df, features, n_clusters=20):\n",
    "    X = df.copy()\n",
    "    X_scaled = X.loc[:, features]\n",
    "    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n",
    "    kmeans = KMeans(n_clusters=20, n_init=50, random_state=0)\n",
    "    X_cd = kmeans.fit_transform(X_scaled)\n",
    "    # Label features and join to dataset\n",
    "    X_cd = pd.DataFrame(\n",
    "        X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])]\n",
    "    )\n",
    "    return X_cd"
   ],
   "id": "ccd26e9cc8964c77",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:34:00.023644Z",
     "start_time": "2025-04-14T16:34:00.001853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PCA\n",
    "def apply_pca(X, standardize=True):\n",
    "    # Standardize\n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Create principal components\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    # Convert to dataframe\n",
    "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "    # Create loadings\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,  # transpose the matrix of loadings\n",
    "        columns=component_names,  # so the columns are the principal components\n",
    "        index=X.columns,  # and the rows are the original features\n",
    "    )\n",
    "    return pca, X_pca, loadings\n",
    "\n",
    "\n",
    "def plot_variance(pca, width=8, dpi=100):\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1, n + 1)\n",
    "    # Explained variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid, evr)\n",
    "    axs[0].set(\n",
    "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
    "    axs[1].set(\n",
    "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
    "    )\n",
    "    # Set up figure\n",
    "    fig.set(figwidth=8, dpi=100)\n",
    "    return axs\n",
    "\n",
    "def pca_inspired(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n",
    "    X[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n",
    "    return X\n",
    "\n",
    "\n",
    "def pca_components(df, features):\n",
    "    X = df.loc[:, features]\n",
    "    _, X_pca, _ = apply_pca(X)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "pca_features = [\n",
    "    \"GarageArea\",  # Площадь гаража\n",
    "    \"YearRemodAdd\",  # Год последнего ремонта\n",
    "    \"TotalBsmtSF\",  # Общая площадь подвала\n",
    "    \"GrLivArea\",  # Жилая площадь над уровнем земли\n",
    "]"
   ],
   "id": "9f6149ea66a1c5b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:34:00.047916Z",
     "start_time": "2025-04-14T16:34:00.027855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def indicate_outliers(df):\n",
    "    \"\"\"Создает бинарные фичи для выбросов.\n",
    "    \n",
    "    У нас есть выбросы, например, дома, которые продаются из частичной собственности. Они имеют огромную площадь, но т.к. частичная продажа - стоят очень дешево. Это мы выяснили благодаря PCA: см. https://alex-podrabinovich.medium.com/%D0%BF%D1%80%D0%BE%D0%B4%D0%B2%D0%B8%D0%BD%D1%83%D1%82%D1%8B%D0%B9-feature-engineering-1e402a4d52a9 \n",
    "    Удалять выбросы мы не будем, конечно, но промаркируем их, чтобы модель могла с ними работать.\n",
    "    \"\"\"\n",
    "    X_new = pd.DataFrame()\n",
    "    X_new[\"Outlier\"] = (df.Neighborhood == \"Edwards\") & (df.SaleCondition == \"Partial\")\n",
    "    return X_new"
   ],
   "id": "eddd70b2dd73355a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:34:00.071294Z",
     "start_time": "2025-04-14T16:34:00.051883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаем preprocessor с разными трансформерами для разных типов данных\n",
    "# Числовые данные пропущенные предсказываем с помощью модели RandomForestRegressor\n",
    "\n",
    "# Пайплайн для числовых признаков (итеративное заполнение)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=50, random_state=RANDOM_STATE),\n",
    "        max_iter=10,\n",
    "        random_state=RANDOM_STATE\n",
    "    )),  # Дает примерно +100 прирост качества vs mean/median\n",
    "    # ('imputer', SimpleImputer(strategy='mean')),\n",
    "    # ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "# Пайплайн для категориальных признаков (заполнение частым значением и кодирование)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    # ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])"
   ],
   "id": "c9a76f52ef0ff30f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:34:00.096766Z",
     "start_time": "2025-04-14T16:34:00.077901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    # Read\n",
    "    data_path = 'data/home-data-for-ml-course'\n",
    "    df_train = pd.read_csv(data_path + '/train.csv', index_col=\"Id\")\n",
    "    df_test = pd.read_csv(data_path + '/test.csv', index_col=\"Id\")\n",
    "\n",
    "    # Merge the splits so we can process them together\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    # Preprocessing\n",
    "    numeric_columns, non_numeric_columns = dm.get_numeric_and_categorical_features(df)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # Применяем к исходным числовым колонкам\n",
    "            ('num', numeric_transformer, numeric_columns),\n",
    "            # Применяем к исходным категориальным колонкам\n",
    "            ('cat', categorical_transformer, non_numeric_columns)\n",
    "        ],\n",
    "        remainder='drop',   # 'passthrough' сохранит полиномиальные и другие колонки, которые не были ни числовыми, ни категориальными ИЗНАЧАЛЬНО\n",
    "        verbose_feature_names_out=False  # Чтобы имена колонок не менялись на 'num__colname' и т.д.\n",
    "    )\n",
    "    df = preprocessor.fit_transform(df)\n",
    "\n",
    "    # Reform splits\n",
    "    df_train = df.loc[df_train.index, :]\n",
    "    df_test = df.loc[df_test.index, :]\n",
    "    \n",
    "    return df_train, df_test"
   ],
   "id": "b7898fd4911ad104",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T16:39:36.217987Z",
     "start_time": "2025-04-14T16:34:00.102888Z"
    }
   },
   "cell_type": "code",
   "source": "df_train, df_test = load_data()",
   "id": "9de2c2ec49bc3afa",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:27:28.282336Z",
     "start_time": "2025-04-14T18:27:28.257911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_features(df, df_test=None):\n",
    "    X = df.copy()\n",
    "    y = X.pop(\"SalePrice\")\n",
    "    \n",
    "    # if df_test is not None:\n",
    "    #     return X, df_test\n",
    "    # return X\n",
    "    \n",
    "    print(f\"Initial X shape: {X.shape}\")\n",
    "    \n",
    "    mi_scores = dm.make_mi_scores(X, y)\n",
    "        \n",
    "    # Combine splits if test data is given\n",
    "    #\n",
    "    # If we're creating features for test set predictions, we should\n",
    "    # use all the data we have available. After creating our features,\n",
    "    # we'll recreate the splits.\n",
    "    if df_test is not None:\n",
    "        X_test = df_test.copy()\n",
    "        X_test.pop(\"SalePrice\")\n",
    "        X = pd.concat([X, X_test])  \n",
    "        print(f\"Final X shape after combine with test: {X.shape}\")\n",
    "\n",
    "    # Mutual Information\n",
    "    # print(f\"Dropping useless features from train set: {X.shape}\")\n",
    "    # X = dm.drop_uninformative(X, mi_scores)\n",
    "    # print(f\"Without useless features: {X.shape}\")\n",
    "\n",
    "    # Transformations\n",
    "    X = X.join(mathematical_transforms(X))\n",
    "    X = X.join(interactions(X))\n",
    "    X = X.join(counts(X))\n",
    "    # X = X.join(break_down(X))\n",
    "    X = X.join(group_transforms(X))\n",
    "    print(f\"X shape after Transformation: {X.shape}\")\n",
    "\n",
    "    # Clustering\n",
    "    # X = X.join(cluster_labels(X, cluster_features, n_clusters=20))\n",
    "    # X = X.join(cluster_distance(X, cluster_features, n_clusters=20))\n",
    "    print(f\"X shape after K-Means: {X.shape}\")\n",
    "\n",
    "    # PCA\n",
    "    X = X.join(pca_inspired(X))\n",
    "    # X = X.join(pca_components(X, pca_features))\n",
    "    # X = X.join(indicate_outliers(X))\n",
    "    print(f\"X shape after PCA: {X.shape}\")\n",
    "\n",
    "    X, _ = dm.label_encode(X)\n",
    "    print(f\"X shape after Label Encoding: {X.shape}\")\n",
    "\n",
    "    # Reform splits\n",
    "    if df_test is not None:\n",
    "        X_test = X.loc[df_test.index, :]\n",
    "        X.drop(df_test.index, inplace=True)\n",
    "    print(f\"X shape after Reform splits: {X.shape}\")\n",
    "        \n",
    "    # # Target Encoder\n",
    "    # encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n",
    "    # X = X.join(encoder.fit_transform(X, y, cols=[\"MSSubClass\"]))  # Тип жилья, участвующего в продаже\n",
    "    # if df_test is not None:\n",
    "    #     X_test = X_test.join(encoder.transform(X_test))\n",
    "    # print(f\"X shape after Target encoding: {X.shape}\")\n",
    "\n",
    "    if df_test is not None:\n",
    "        return X, X_test\n",
    "    else:\n",
    "        return X"
   ],
   "id": "3e43904c563d67c1",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:27:29.098176Z",
     "start_time": "2025-04-14T18:27:28.761195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = create_features(df_train)\n",
    "y_train = df_train.loc[:, \"SalePrice\"]\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ],
   "id": "ffec3bff3f27bcbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial X shape: (1460, 79)\n",
      "X shape after Transformation: (1460, 96)\n",
      "X shape after K-Means: (1460, 96)\n",
      "X shape after PCA: (1460, 98)\n",
      "X shape after Label Encoding: (1460, 98)\n",
      "X shape after Reform splits: (1460, 98)\n",
      "(1460, 98)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                          \n",
       "1         60.0         65.0   8450.0          7.0          5.0     2003.0   \n",
       "2         20.0         80.0   9600.0          6.0          8.0     1976.0   \n",
       "3         60.0         68.0  11250.0          7.0          5.0     2001.0   \n",
       "4         70.0         60.0   9550.0          7.0          5.0     1915.0   \n",
       "5         60.0         84.0  14260.0          8.0          5.0     2000.0   \n",
       "\n",
       "    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  TotalQualScore  \\\n",
       "Id                                                    ...                   \n",
       "1         2003.0       196.0       706.0         0.0  ...              24   \n",
       "2         1976.0         0.0       978.0         0.0  ...              21   \n",
       "3         2002.0       162.0       486.0         0.0  ...              23   \n",
       "4         1970.0         0.0       216.0         0.0  ...              21   \n",
       "5         2000.0       350.0       655.0         0.0  ...              23   \n",
       "\n",
       "    PorchDeckArea  HasPorchDeck  HasFireplace  HasGarage  HasFence  \\\n",
       "Id                                                                   \n",
       "1            61.0             1             0          1         1   \n",
       "2           298.0             1             1          1         1   \n",
       "3            42.0             1             1          1         1   \n",
       "4           307.0             1             1          1         1   \n",
       "5           276.0             1             1          1         1   \n",
       "\n",
       "    PorchTypes  MedNhbdArea  Feature1   Feature2  \n",
       "Id                                                \n",
       "1            1       1500.0    2566.0  1714568.0  \n",
       "2            1       1437.0    2524.0  2493712.0  \n",
       "3            1       1500.0    2706.0  1841840.0  \n",
       "4            2       1717.0    2473.0  1489320.0  \n",
       "5            2       2418.0    3343.0  2290000.0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalQualScore</th>\n",
       "      <th>PorchDeckArea</th>\n",
       "      <th>HasPorchDeck</th>\n",
       "      <th>HasFireplace</th>\n",
       "      <th>HasGarage</th>\n",
       "      <th>HasFence</th>\n",
       "      <th>PorchTypes</th>\n",
       "      <th>MedNhbdArea</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>1714568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>2524.0</td>\n",
       "      <td>2493712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2706.0</td>\n",
       "      <td>1841840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>1489320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>3343.0</td>\n",
       "      <td>2290000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Валидация",
   "id": "b5bca17f7faeade8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:24:00.833297Z",
     "start_time": "2025-04-14T18:24:00.803585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "catboost_params = {\n",
    "    'iterations': 1000, \n",
    "    'learning_rate': 0.05, \n",
    "    'depth': 6, \n",
    "    'loss_function': 'RMSE', \n",
    "    'verbose': 0, \n",
    "    'random_seed': RANDOM_STATE,\n",
    "    'early_stopping_rounds': 100  # ?\n",
    "}"
   ],
   "id": "2c9455dbfbd74019",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:24:06.988260Z",
     "start_time": "2025-04-14T18:24:02.495436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Пояснения к тому, что тут происходит:\n",
    "\n",
    "Тут мы ОЦЕНИВАЕМ и ТЕСТИРУЕМ подобранные фичи и гиперпараметры. В цикле бежим по N_FOLD-ам, бьем данные тренировочные в соотношении 80% на обучение, 20% на валидацию. Обучаем модель на трейне, валидируем на валидации. Смотрим на ошибки. Если по итогу нас все устраивает, мы дальше идем и обучаем модель с нуля на всех данных со всеми гиперпараметрами и фичами (да еще можно вычленить из цикла итерацию самую лучшую для нужного количества итераций обучения финальной модели),\n",
    "\n",
    "oof_predictions — это массив, который в итоге будет содержать предсказания для каждого объекта из исходного тренировочного набора (X). Важно, что предсказание для конкретного объекта (например, дома №100) делается той моделью (из цикла CV), которая обучалась без этого объекта. Надежная оценка качества: OOF-предикты позволяют посчитать метрику качества (например, oof_rmse) на всем тренировочном наборе, при этом каждое предсказание было сделано \"честно\" (модель не видела этот объект при обучении). \n",
    "Эта оценка часто бывает более надежной, чем простое усреднение метрик по фолдам (mean_cv_rmse), так как она считается на полном наборе данных один раз. \n",
    "Можно сравнить oof_predictions с реальными значениями y_log (или y), чтобы понять, на каких объектах модель ошибается сильнее всего.\n",
    "Стэкинг/Блендинг: OOF-предикты часто используются как новые признаки для обучения модели второго уровня (мета-модели) в ансамблях (стэкинг).\n",
    "\"\"\"\n",
    "\n",
    "# --- Кросс-Валидация ---\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "oof_predictions = np.zeros(X_train.shape[0])  # Для хранения out-of-fold предсказаний\n",
    "fold_rmses = []\n",
    "fold_best_iterations = []  # Будем сохранять лучшие итерации\n",
    "\n",
    "mlflow.set_experiment(\"KFold Default With improved features v1\")\n",
    "with mlflow.start_run() as run:  # Сохраняем run для логирования артефактов\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)): \n",
    "        print(f\"--- Fold {fold+1}/{N_FOLDS} ---\")\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Обучаем модель с early stopping\n",
    "        model = CatBoostRegressor(**catboost_params)\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_val_fold, y_val_fold)],\n",
    "                  verbose=0,  # Отключаем вывод, 100 - если хотим видеть обучение \n",
    "                 )\n",
    "\n",
    "        # Сохраняем лучшую итерацию\n",
    "        best_iter = model.get_best_iteration()\n",
    "        fold_best_iterations.append(best_iter)\n",
    "        print(f\"Best iteration for fold {fold+1}: {best_iter}\")\n",
    "\n",
    "        # 4. Предсказания на валидации\n",
    "        val_preds = model.predict(X_val_fold)\n",
    "        oof_predictions[val_idx] = val_preds\n",
    "\n",
    "        # Оценка на фолде\n",
    "        fold_rmsle = np.sqrt(mean_squared_error(np.log(y_val_fold), np.log(val_preds)))\n",
    "        print(f\"Fold {fold+1} RMSLE: {fold_rmsle}\")\n",
    "        fold_rmses.append(fold_rmsle)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_rmsle\", fold_rmsle, step=fold+1)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_best_iter\", best_iter, step=fold+1)\n",
    "    \n",
    "    # --- Итоговая оценка CV ---\n",
    "    mean_cv_rmse = np.mean(fold_rmses)\n",
    "    std_cv_rmse = np.std(fold_rmses)\n",
    "    oof_rmse = np.sqrt(mean_squared_error(np.log(y_train), np.log(oof_predictions)))\n",
    "\n",
    "    print(f\"\\nMean CV RMSLE: {mean_cv_rmse:.4f} +/- {std_cv_rmse:.4f}\")\n",
    "    print(f\"OOF RMSLE: {oof_rmse:.4f}\")\n",
    "    print(f\"Mean best iteration: {np.mean(fold_best_iterations):.0f}\")\n",
    "\n",
    "    # Логгирование итоговых метрик вручную\n",
    "    mlflow.log_metric(\"mean_cv_rmse\", mean_cv_rmse)\n",
    "    mlflow.log_metric(\"std_cv_rmse\", std_cv_rmse)\n",
    "    mlflow.log_metric(\"oof_rmse\", oof_rmse)\n",
    "    mlflow.log_metric(\"mean_best_iteration\", np.mean(fold_best_iterations))"
   ],
   "id": "42392c4ea4745179",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1/5 ---\n",
      "Best iteration for fold 1: 751\n",
      "Fold 1 RMSLE: 0.13268481962928946\n",
      "--- Fold 2/5 ---\n",
      "Best iteration for fold 2: 821\n",
      "Fold 2 RMSLE: 0.10707061671863766\n",
      "--- Fold 3/5 ---\n",
      "Best iteration for fold 3: 62\n",
      "Fold 3 RMSLE: 0.16698609472454448\n",
      "--- Fold 4/5 ---\n",
      "Best iteration for fold 4: 903\n",
      "Fold 4 RMSLE: 0.12427656760319122\n",
      "--- Fold 5/5 ---\n",
      "Best iteration for fold 5: 984\n",
      "Fold 5 RMSLE: 0.10361146417006144\n",
      "\n",
      "Mean CV RMSLE: 0.1269 +/- 0.0227\n",
      "OOF RMSLE: 0.1289\n",
      "Mean best iteration: 704\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:23:11.587581Z",
     "start_time": "2025-04-14T18:23:11.565075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# К чему стремимся\n",
    "# --- Fold 1/5 ---\n",
    "# Best iteration for fold 1: 626\n",
    "# Fold 1 RMSLE: 0.12822565845390327\n",
    "# --- Fold 2/5 ---\n",
    "# Best iteration for fold 2: 916\n",
    "# Fold 2 RMSLE: 0.10662773995346779\n",
    "# --- Fold 3/5 ---\n",
    "# Best iteration for fold 3: 594\n",
    "# Fold 3 RMSLE: 0.13932657522708686\n",
    "# --- Fold 4/5 ---\n",
    "# Best iteration for fold 4: 710\n",
    "# Fold 4 RMSLE: 0.12416343423096966\n",
    "# --- Fold 5/5 ---\n",
    "# Best iteration for fold 5: 997\n",
    "# Fold 5 RMSLE: 0.10615331382371691\n",
    "# \n",
    "# Mean CV RMSLE: 0.1209 +/- 0.0128\n",
    "# OOF RMSLE: 0.1216\n",
    "# Mean best iteration: 769\n",
    "\n"
   ],
   "id": "9d642e950c1bf76a",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:11:38.114878Z",
     "start_time": "2025-04-14T18:11:38.094118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter Tuning here...\n",
    "# X_train = create_features(df_train)\n",
    "# y_train = df_train.loc[:, \"SalePrice\"]\n",
    "# \n",
    "# xgb_params = dict(\n",
    "#     max_depth=6,           # maximum depth of each tree - try 2 to 10\n",
    "#     learning_rate=0.01,    # effect of each tree - try 0.0001 to 0.1\n",
    "#     n_estimators=1000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n",
    "#     min_child_weight=1,    # minimum number of houses in a leaf - try 1 to 10\n",
    "#     colsample_bytree=0.7,  # fraction of features (columns) per tree - try 0.2 to 1.0\n",
    "#     subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n",
    "#     reg_alpha=0.5,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n",
    "#     reg_lambda=1.0,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n",
    "#     num_parallel_tree=1,   # set > 1 for boosted random forests\n",
    "# )\n",
    "# \n",
    "# xgb = XGBRegressor(**xgb_params)\n",
    "# score_dataset(X_train, y_train, xgb)"
   ],
   "id": "117164948d6b0ee8",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Финальная модель и submission",
   "id": "4f3ef61e1a102ae1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:24:13.667648Z",
     "start_time": "2025-04-14T18:24:11.820384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Model and Create Submissions\n",
    "X_train, X_test = create_features(df_train, df_test)\n",
    "y_train = df_train.loc[:, \"SalePrice\"]\n",
    "\n",
    "final_iterations = 1000\n",
    "final_catboost_params = catboost_params.copy()\n",
    "final_catboost_params['iterations'] = final_iterations\n",
    "final_catboost_params.pop('early_stopping_rounds', None)  # Убираем early stopping для финального обучения\n",
    "print(f\"Финальные параметры обучения модели: {final_catboost_params}\")\n",
    "\n",
    "final_model = CatBoostRegressor(**final_catboost_params)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Final model trained.\")"
   ],
   "id": "fe835444254b35f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial X shape: (1460, 79)\n",
      "Final X shape after combine with test: (2919, 79)\n",
      "X shape after Transformation: (2919, 96)\n",
      "X shape after K-Means: (2919, 96)\n",
      "X shape after PCA: (2919, 98)\n",
      "X shape after Label Encoding: (2919, 98)\n",
      "X shape after Reform splits: (1460, 98)\n",
      "X shape after Target encoding: (1460, 99)\n",
      "Финальные параметры обучения модели: {'iterations': 1000, 'learning_rate': 0.05, 'depth': 6, 'loss_function': 'RMSE', 'verbose': 0, 'random_seed': 42}\n",
      "Final model trained.\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:24:16.333851Z",
     "start_time": "2025-04-14T18:24:16.297359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Предсказание на тест данных для сабмишна\n",
    "predictions = final_model.predict(X_test)\n",
    "submission_single = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\n",
    "submission_single.to_csv('final_FE_v13.csv', index=False)\n",
    "submission_single.head()"
   ],
   "id": "6f3a4bba134e76f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  120825.414040\n",
       "1  1462  166370.184723\n",
       "2  1463  190696.698673\n",
       "3  1464  198871.919007\n",
       "4  1465  187180.335068"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>120825.414040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>166370.184723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>190696.698673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>198871.919007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>187180.335068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==============================================================\n",
    "# ==============================================================\n",
    "# =============================================================="
   ],
   "id": "7f8f8c29d5680438"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:52:33.249490Z",
     "start_time": "2025-04-07T12:52:33.171420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kaggle BASELINE\n",
    "\n",
    "# 12879.10346"
   ],
   "id": "d9dab3fec7be6d4b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "efa1167d6750a138"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
