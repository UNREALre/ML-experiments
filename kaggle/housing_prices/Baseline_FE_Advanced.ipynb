{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# KFold + Catboost Baseline + Advanced Feature Engineering\n",
    "Накручиваем поверх Baseline продвинутое FE."
   ],
   "id": "29102a4f1e062b26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:37.157495Z",
     "start_time": "2025-04-07T12:41:33.443722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Вместо одного фиксированного разбиения на train/test используем стабильную стратегию кросс-валидации.\n",
    "# Используем тут Cross-validation, потому что:\n",
    "# \t•\tнужно надёжно сравнить несколько разных моделей или гиперпараметров и понять, какая модель стабильнее и лучше в целом.\n",
    "# \t•\tхотим избежать случайных удач или провалов, связанных с конкретным разбиением на train/test.\n",
    "# \t•\tвыбираем модель или гиперпараметры, которые потом будешь использовать для финального сабмишна на Kaggle.\n",
    "# Делаем эту оценку, чтобы в дальнейших блокнотах-улучшениях сравнивать более корректно.\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score, train_test_split\n",
    "\n",
    "# Используем IterativeImputer:\n",
    "# \t•\tОн итеративно заполняет все пропуски сразу.\n",
    "# \t•\tРаботает одновременно со всеми признаками, учитывая связи между ними.\n",
    "# \t•\tНе требует ручного управления порядком заполнения.\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from utils.data_manager import DataManager\n",
    "from utils.model_manager import ModelManager\n",
    "from utils.syth_generator_gaussian import CombinedSyntheticGenerator"
   ],
   "id": "d815cc32b92f72fe",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:37.936438Z",
     "start_time": "2025-04-07T12:41:37.869635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Глобально включаем вывод Pandas для всех трансформеров ---\n",
    "# (Можно применять и к отдельным трансформерам/пайплайнам .set_output(transform=\"pandas\"))\n",
    "set_config(transform_output = \"pandas\")"
   ],
   "id": "cbe9224fd4e2b5dc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:38.110770Z",
     "start_time": "2025-04-07T12:41:38.073852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dm = DataManager()\n",
    "mm = ModelManager()\n",
    "\n",
    "# Отключаем автологгирование, чтобы использовать ручное\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "warnings.filterwarnings(\"ignore\", module=\"mlflow\")  # Игнорируем предупреждения MLflow\n"
   ],
   "id": "7228dc2937707f33",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:38.148044Z",
     "start_time": "2025-04-07T12:41:38.117993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5  # Например, 5 или 10"
   ],
   "id": "a3e055dca20f3884",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Загрузка данных",
   "id": "221fb75297067ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:38.214844Z",
     "start_time": "2025-04-07T12:41:38.160573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = 'data/home-data-for-ml-course'\n",
    "train_data = pd.read_csv(data_path + '/train.csv')\n",
    "test_data = pd.read_csv(data_path + '/test.csv')\n",
    "train_data.shape"
   ],
   "id": "fc47de32480cc60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Предобработка данных ",
   "id": "7b2a25badd3fdad2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:44.262744Z",
     "start_time": "2025-04-07T12:41:44.169869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Определение колонок для удаления\n",
    "intuitively_bad_features = [\n",
    "    'LotShape',  # Общая форма участка\n",
    "    'LandContour',  # Рельеф участка\n",
    "    'LotConfig',  # Конфигурация участка\n",
    "    'LandSlope',  # Уклон участка\n",
    "    'MiscFeature',\n",
    "    'MiscVal',\n",
    "]\n",
    "bad_columns = dm.get_all_nan_cols(train_data)\n",
    "bad_columns.append('Id')\n",
    "bad_columns.extend(intuitively_bad_features)"
   ],
   "id": "399272bf33bbd0f9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:45.388859Z",
     "start_time": "2025-04-07T12:41:45.345493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Разделение на X / y\n",
    "X, y = dm.split_data_set_to_x_y(train_data, 'SalePrice')\n",
    "print(X.shape, y.shape)\n",
    "X_test = test_data.copy()\n",
    "print(X_test.shape)"
   ],
   "id": "3f580e8449fd2024",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80) (1460,)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:53.569936Z",
     "start_time": "2025-04-07T12:41:53.512223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X.drop(columns=bad_columns, inplace=True)\n",
    "X_test.drop(columns=bad_columns, inplace=True)"
   ],
   "id": "49486958df3120dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:41:56.455694Z",
     "start_time": "2025-04-07T12:41:56.416429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_feature_eng_great_again(train_X_in, test_X_in):\n",
    "    \"\"\"Хелпер, который создает фичи, логарифмирует и выравнивает колонки.\"\"\"\n",
    "    # Работаем с копиями, чтобы не изменять оригинальные X, X_test вне функции\n",
    "    train_X = train_X_in.copy()\n",
    "    test_X = test_X_in.copy()\n",
    "\n",
    "    # Словарь качественных признаков\n",
    "    quality_dict = {'Ex': 5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.nan:0}\n",
    "\n",
    "    def create_features(df):\n",
    "        # Interactions (с проверкой на наличие колонок)\n",
    "        if 'Neighborhood' in df.columns and 'MSZoning' in df.columns:\n",
    "            df['Neighborhood_Zoning'] = df['Neighborhood'].astype(str) + '_' + df['MSZoning'].astype(str)\n",
    "            # df.drop(columns=['Neighborhood', 'MSZoning'], inplace=True)  # mean CV RMSLE улучшился на 0.008, oof rmse улучшился на 0.0011; KAGGLE LB УПАЛ!!!\n",
    "        if 'SaleType' in df.columns and 'SaleCondition' in df.columns:\n",
    "            df['SaleType_Condition'] = df['SaleType'].astype(str) + '_' + df['SaleCondition'].astype(str)\n",
    "            # df.drop(columns=['SaleType', 'SaleCondition'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        # Quality Score\n",
    "        df['TotalQualScore'] = 0\n",
    "        quality_cols = ['ExterQual', 'KitchenQual', 'BsmtQual', 'HeatingQC', 'GarageQual', 'FireplaceQu']\n",
    "        for col in quality_cols:\n",
    "            if col in df.columns:\n",
    "                 df['TotalQualScore'] += df[col].map(quality_dict).fillna(0)\n",
    "        # df.drop(columns=quality_cols, inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        # Porch/Deck Area and Flags\n",
    "        df['PorchDeckArea'] = 0\n",
    "        porch_cols = ['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n",
    "        for col in porch_cols:\n",
    "             if col in df.columns:\n",
    "                df['PorchDeckArea'] += df[col].fillna(0)\n",
    "        # df.drop(columns=porch_cols, inplace=True)  # Mean CV RMSE улучшился на 0.0008, oof rmse улучшился на 0.0006; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        if 'Fireplaces' in df.columns:\n",
    "            df['HasFireplace'] = (df['Fireplaces'] > 0).astype(int)\n",
    "            # df.drop(columns=['Fireplaces'], inplace=True)  # !!! mean cv rmse улучшился на 0.0023, oof rmse улучшился на 0.0031. fold 3 проблемный очень хорошо улучшился без этой фичи; KAGGLE LB УПАЛ!!!\n",
    "        if 'GarageType' in df.columns:\n",
    "            df['HasGarage'] = (~df['GarageType'].isna()).astype(int)\n",
    "            # df.drop(columns=['GarageType'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "        if 'Fence' in df.columns:\n",
    "            df['HasFence'] = (~df['Fence'].isna()).astype(int)\n",
    "            # df.drop(columns=['Fence'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "        df['HasPorchDeck'] = (df['PorchDeckArea'] > 0).astype(int)\n",
    "        # df.drop(columns=['PorchDeckArea'], inplace=True)  # ошибка увеличилась; KAGGLE LB УПАЛ!!!\n",
    "\n",
    "        return df\n",
    "\n",
    "    def log_features(df, cols_to_log_list):  # Принимает СПИСОК колонок\n",
    "        print(f\"Applying log1p to: {cols_to_log_list}\")\n",
    "        for col_name in cols_to_log_list:\n",
    "            if col_name in df.columns:\n",
    "                # Добавим проверку на отрицательные значения перед логарифмированием\n",
    "                if (df[col_name] < 0).any():\n",
    "                     print(f\"Warning: Column {col_name} contains negative values. Skipping log1p.\")\n",
    "                else:\n",
    "                    df[col_name] = np.log1p(df[col_name])\n",
    "            else:\n",
    "                print(f\"Warning: Column {col_name} not found in DF during log transform.\")\n",
    "        return df\n",
    "\n",
    "    # 1. Создаем фичи\n",
    "    train_X = create_features(train_X)\n",
    "    test_X = create_features(test_X)\n",
    "    print(\"Features created.\")\n",
    "\n",
    "    # 2. Определяем колонки для логарифмирования (ТОЛЬКО по трейну)\n",
    "    numeric_cols = train_X.select_dtypes(include=np.number).columns\n",
    "    skew_values = train_X[numeric_cols].skew()\n",
    "    # Используем .index.tolist() чтобы получить список имен\n",
    "    cols_to_log_list = skew_values[skew_values > 1].index.tolist()\n",
    "    print(f\"Columns identified for logging: {cols_to_log_list}\")\n",
    "\n",
    "    # # 3. Логарифмируем (используя ОДИН и тот же список)\n",
    "    # train_X = log_features(train_X, cols_to_log_list)\n",
    "    # test_X = log_features(test_X, cols_to_log_list)\n",
    "    # print(\"Log transform applied.\")\n",
    "\n",
    "    # 4. Согласуем и сортируем колонки ПОСЛЕ всех манипуляций\n",
    "    final_feature_cols = sorted(train_X.columns.tolist()) # Сортируем для стабильности\n",
    "    train_X = train_X[final_feature_cols]\n",
    "    test_X = test_X.reindex(columns=final_feature_cols, fill_value=0)\n",
    "    print(\"Columns aligned and sorted.\")\n",
    "\n",
    "    return train_X, test_X"
   ],
   "id": "f18e4aa4b623373a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:42:01.998217Z",
     "start_time": "2025-04-07T12:42:01.920078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Вызываем функцию с правильными данными (X, X_test)\n",
    "X, X_test = make_feature_eng_great_again(X, X_test)\n",
    "\n",
    "print(\"\\nProcessing complete. Final shapes:\")\n",
    "print(f\"X_processed: {X.shape}\")\n",
    "print(f\"X_test_processed: {X_test.shape}\")\n",
    "print(\"\\nExample processed X:\")\n",
    "print(X.head())"
   ],
   "id": "ffec3bff3f27bcbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created.\n",
      "Columns identified for logging: ['MSSubClass', 'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtHalfBath', 'KitchenAbvGr', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PorchDeckArea', 'HasFence']\n",
      "Columns aligned and sorted.\n",
      "\n",
      "Processing complete. Final shapes:\n",
      "X_processed: (1460, 81)\n",
      "X_test_processed: (1459, 81)\n",
      "\n",
      "Example processed X:\n",
      "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
      "0       856       854          0   NaN             3     1Fam       TA   \n",
      "1      1262         0          0   NaN             3     1Fam       TA   \n",
      "2       920       866          0   NaN             3     1Fam       TA   \n",
      "3       961       756          0   NaN             3     1Fam       Gd   \n",
      "4      1145      1053          0   NaN             4     1Fam       TA   \n",
      "\n",
      "  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ... ScreenPorch Street  TotRmsAbvGrd  \\\n",
      "0           No         706           0  ...           0   Pave             8   \n",
      "1           Gd         978           0  ...           0   Pave             6   \n",
      "2           Mn         486           0  ...           0   Pave             6   \n",
      "3           No         216           0  ...           0   Pave             7   \n",
      "4           Av         655           0  ...           0   Pave             9   \n",
      "\n",
      "   TotalBsmtSF TotalQualScore  Utilities WoodDeckSF YearBuilt YearRemodAdd  \\\n",
      "0          856             20     AllPub          0      2003         2003   \n",
      "1         1262             21     AllPub        298      1976         1976   \n",
      "2          920             23     AllPub          0      2001         2002   \n",
      "3          756             21     AllPub          0      1915         1970   \n",
      "4         1145             23     AllPub        192      2000         2000   \n",
      "\n",
      "  YrSold  \n",
      "0   2008  \n",
      "1   2007  \n",
      "2   2008  \n",
      "3   2006  \n",
      "4   2008  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:42:04.072201Z",
     "start_time": "2025-04-07T12:42:03.990460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Получение числовых колонок\n",
    "numeric_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "# Получение нечисловых колонок (всех остальных)\n",
    "non_numeric_columns = X.select_dtypes(exclude=['float64', 'int64']).columns"
   ],
   "id": "5966d1edb7cfd83b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Обучаем модель с CV и корректируя данные",
   "id": "91a81bb0c6a6112e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Нормализация данных через ColumnTransformer и Pipeline\n",
    "В данном кейсе мы реализуем Заполнение числовых пропусков с помощью модели (Predictive imputation). Т.е. то, что пропущено в числовых признаках - будем заполнять не медианой или средним, а будем обучать модель, которая будет предсказывать пропуски (IterativeImputer + RandomForestRegressor)"
   ],
   "id": "41ed5a257a4eec8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:42:21.426131Z",
     "start_time": "2025-04-07T12:42:21.352180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаем preprocessor с разными трансформерами для разных типов данных\n",
    "# Числовые данные пропущенные предсказываем с помощью модели RandomForestRegressor\n",
    "\n",
    "# Пайплайн для числовых признаков (итеративное заполнение)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=50, random_state=RANDOM_STATE),\n",
    "        max_iter=10,\n",
    "        random_state=RANDOM_STATE\n",
    "    )),  # Дает примерно +100 прирост качества vs mean/median\n",
    "    # ('imputer', SimpleImputer(strategy='mean')),\n",
    "    # ('scaler', StandardScaler())  # разницы не дает \n",
    "])\n",
    "\n",
    "# Пайплайн для категориальных признаков (заполнение частым значением и кодирование)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# --- Объединяем препроцессоры ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Применяем к исходным числовым колонкам\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        # Применяем к исходным категориальным колонкам\n",
    "        ('cat', categorical_transformer, non_numeric_columns)\n",
    "    ],\n",
    "    remainder='drop',   # 'passthrough' сохранит полиномиальные и другие колонки, которые не были ни числовыми, ни категориальными ИЗНАЧАЛЬНО\n",
    "    verbose_feature_names_out=False  # Чтобы имена колонок не менялись на 'num__colname' и т.д.\n",
    ")\n",
    "\n",
    "default_params = {\n",
    "    'iterations': 1000, \n",
    "    'learning_rate': 0.05, \n",
    "    'depth': 6, \n",
    "    'loss_function': 'RMSE', \n",
    "    'verbose': 0, \n",
    "    'random_seed': RANDOM_STATE,\n",
    "    'early_stopping_rounds': 100  # ?\n",
    "}\n",
    "catboost_params = default_params\n",
    "\n",
    "\n",
    "# Включить Early Stopping очень рекомендуется в параметрах. Это позволит модели на каждом фолде останавливаться тогда, когда метрика на валидационной части этого фолда (X_val, y_val_log) перестает улучшаться. Это самый надежный способ подобрать оптимальное число итераций для каждого фолда и избежать переобучения\n",
    "\n",
    "# --- Финальный пайплайн ---\n",
    "# Мы будем использовать preprocessor и модель отдельно в цикле CV\n",
    "# для корректной работы early stopping с пайплайном sklearn. Поэтому нам финальный пайплайн - не нужен.\n",
    "# final_pipeline = Pipeline([\n",
    "#     ('preprocessing', preprocessor),\n",
    "#     ('model', CatBoostRegressor(**catboost_params))\n",
    "# ])"
   ],
   "id": "6ff53557f62da732",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:45:47.989088Z",
     "start_time": "2025-04-07T12:43:48.324001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Пояснения к тому, что тут происходит:\n",
    "\n",
    "Тут мы ОЦЕНИВАЕМ и ТЕСТИРУЕМ подобранные фичи и гиперпараметры. В цикле бежим по N_FOLD-ам, бьем данные тренировочные в соотношении 80% на обучение, 20% на валидацию. Обучаем модель на трейне, валидируем на валидации. Смотрим на ошибки. Если по итогу нас все устраивает, мы дальше идем и обучаем модель с нуля на всех данных со всеми гиперпараметрами и фичами (да еще можно вычленить из цикла итерацию самую лучшую для нужного количества итераций обучения финальной модели),\n",
    "\n",
    "oof_predictions — это массив, который в итоге будет содержать предсказания для каждого объекта из исходного тренировочного набора (X). Важно, что предсказание для конкретного объекта (например, дома №100) делается той моделью (из цикла CV), которая обучалась без этого объекта. Надежная оценка качества: OOF-предикты позволяют посчитать метрику качества (например, oof_rmse) на всем тренировочном наборе, при этом каждое предсказание было сделано \"честно\" (модель не видела этот объект при обучении). \n",
    "Эта оценка часто бывает более надежной, чем простое усреднение метрик по фолдам (mean_cv_rmse), так как она считается на полном наборе данных один раз. \n",
    "Можно сравнить oof_predictions с реальными значениями y_log (или y), чтобы понять, на каких объектах модель ошибается сильнее всего.\n",
    "Стэкинг/Блендинг: OOF-предикты часто используются как новые признаки для обучения модели второго уровня (мета-модели) в ансамблях (стэкинг).\n",
    "\"\"\"\n",
    "\n",
    "# --- Кросс-Валидация ---\n",
    "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# # --- Кросс-Валидация с учетом временной структуры ---\n",
    "# tscv = TimeSeriesSplit(n_splits=N_FOLDS, test_size=int(0.19*len(X)))\n",
    "\n",
    "oof_predictions = np.zeros(X.shape[0])  # Для хранения out-of-fold предсказаний\n",
    "fold_rmses = []\n",
    "fold_best_iterations = []  # Будем сохранять лучшие итерации\n",
    "\n",
    "mlflow.set_experiment(\"KFold Default With improved features\")\n",
    "with mlflow.start_run() as run:  # Сохраняем run для логирования артефактов\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)): \n",
    "        print(f\"--- Fold {fold+1}/{N_FOLDS} ---\")\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # 1. Обучаем препроцессор ТОЛЬКО на трейне текущего фолда\n",
    "        preprocessor.fit(X_train)\n",
    "\n",
    "        # 2. Трансформируем трейн и валидацию\n",
    "        X_train_prep = preprocessor.transform(X_train)\n",
    "        X_val_prep = preprocessor.transform(X_val)\n",
    "\n",
    "        # 3. Обучаем модель с early stopping\n",
    "        model = CatBoostRegressor(**catboost_params)\n",
    "        model.fit(X_train_prep, y_train,\n",
    "                  eval_set=[(X_val_prep, y_val)],\n",
    "                  verbose=0,  # Отключаем вывод, 100 - если хотим видеть обучение \n",
    "                 )\n",
    "\n",
    "        # Сохраняем лучшую итерацию\n",
    "        best_iter = model.get_best_iteration()\n",
    "        fold_best_iterations.append(best_iter)\n",
    "        print(f\"Best iteration for fold {fold+1}: {best_iter}\")\n",
    "\n",
    "        # 4. Предсказания на валидации\n",
    "        val_preds = model.predict(X_val_prep)\n",
    "        oof_predictions[val_idx] = val_preds\n",
    "\n",
    "        # 5. Оценка на фолде\n",
    "        # Берем логарифмы, т.к. так оценивает Kaggle по условиям задачи\n",
    "        fold_rmse = np.sqrt(mean_squared_error(np.log(y_val), np.log(val_preds)))\n",
    "        print(f\"Fold {fold+1} RMSE: {fold_rmse}\")\n",
    "        fold_rmses.append(fold_rmse)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_rmse\", fold_rmse, step=fold+1)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_best_iter\", best_iter, step=fold+1)\n",
    "    \n",
    "    # --- Итоговая оценка CV ---\n",
    "    mean_cv_rmse = np.mean(fold_rmses)\n",
    "    std_cv_rmse = np.std(fold_rmses)\n",
    "    oof_rmse = np.sqrt(mean_squared_error(np.log(y), np.log(oof_predictions)))\n",
    "\n",
    "    print(f\"\\nMean CV RMSE: {mean_cv_rmse:.4f} +/- {std_cv_rmse:.4f}\")\n",
    "    print(f\"OOF RMSE: {oof_rmse:.4f}\")\n",
    "    print(f\"Mean best iteration: {np.mean(fold_best_iterations):.0f}\")\n",
    "\n",
    "    # Логгирование итоговых метрик вручную\n",
    "    mlflow.log_metric(\"mean_cv_rmse\", mean_cv_rmse)\n",
    "    mlflow.log_metric(\"std_cv_rmse\", std_cv_rmse)\n",
    "    mlflow.log_metric(\"oof_rmse\", oof_rmse)\n",
    "    mlflow.log_metric(\"mean_best_iteration\", np.mean(fold_best_iterations))"
   ],
   "id": "4ebdc2aca4c61798",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1/5 ---\n",
      "Best iteration for fold 1: 988\n",
      "Fold 1 RMSE: 0.13268676307211907\n",
      "--- Fold 2/5 ---\n",
      "Best iteration for fold 2: 947\n",
      "Fold 2 RMSE: 0.11501482412109708\n",
      "--- Fold 3/5 ---\n",
      "Best iteration for fold 3: 60\n",
      "Fold 3 RMSE: 0.17362179092361715\n",
      "--- Fold 4/5 ---\n",
      "Best iteration for fold 4: 585\n",
      "Fold 4 RMSE: 0.1257864222951497\n",
      "--- Fold 5/5 ---\n",
      "Best iteration for fold 5: 808\n",
      "Fold 5 RMSE: 0.10139931418277556\n",
      "\n",
      "Mean CV RMSE: 0.1297 +/- 0.0244\n",
      "OOF RMSE: 0.1320\n",
      "Mean best iteration: 678\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3405a0b56d012fc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:52:43.313808Z",
     "start_time": "2025-04-07T12:52:43.215963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# К чему стремимся\n",
    "# --- Fold 1/5 ---\n",
    "# Best iteration for fold 1: 988\n",
    "# Fold 1 RMSE: 0.13268676307211907\n",
    "# --- Fold 2/5 ---\n",
    "# Best iteration for fold 2: 947\n",
    "# Fold 2 RMSE: 0.11501482412109708\n",
    "# --- Fold 3/5 ---\n",
    "# Best iteration for fold 3: 60\n",
    "# Fold 3 RMSE: 0.17362179092361715\n",
    "# --- Fold 4/5 ---\n",
    "# Best iteration for fold 4: 585\n",
    "# Fold 4 RMSE: 0.1257864222951497\n",
    "# --- Fold 5/5 ---\n",
    "# Best iteration for fold 5: 808\n",
    "# Fold 5 RMSE: 0.10139931418277556\n",
    "# \n",
    "# Mean CV RMSE: 0.1297 +/- 0.0244\n",
    "# OOF RMSE: 0.1320\n",
    "# Mean best iteration: 678\n",
    "\n"
   ],
   "id": "32825bfda0701507",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:46:42.347030Z",
     "start_time": "2025-04-07T12:46:09.016916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# На прошлом шаге мы сделали KFOLD обучение, если довольны метриками, то получаем лучшую итерацию и обучаем финальную модель на ВСЕХ данных.\n",
    "\n",
    "final_iterations = catboost_params['iterations']  # optuna нашла уже лучшие параметры\n",
    "# Используем среднее реальных лучших итераций из CV\n",
    "# final_iterations = int(np.mean(fold_best_iterations))\n",
    "# Или можно попробовать медиану, она менее чувствительна к выбросам (как Fold 3)\n",
    "# final_iterations = int(np.median(fold_best_iterations))\n",
    "# final_iterations = best_final_iterations\n",
    "\n",
    "print(f\"\\nTraining final model on all data with {final_iterations} iterations...\")\n",
    "\n",
    "final_catboost_params = catboost_params.copy()\n",
    "final_catboost_params['iterations'] = final_iterations\n",
    "final_catboost_params.pop('early_stopping_rounds', None)  # Убираем early stopping для финального обучения\n",
    "print(f\"Финальные параметры обучения модели: {final_catboost_params}\")\n",
    "\n",
    "final_model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', CatBoostRegressor(**final_catboost_params))\n",
    "])\n",
    "\n",
    "final_model_pipeline.fit(X, y)\n",
    "print(\"Final model trained.\")"
   ],
   "id": "cf2ffc93d8f27bd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training final model on all data with 1000 iterations...\n",
      "Финальные параметры обучения модели: {'iterations': 1000, 'learning_rate': 0.05, 'depth': 6, 'loss_function': 'RMSE', 'verbose': 0, 'random_seed': 42}\n",
      "Final model trained.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:46:42.557448Z",
     "start_time": "2025-04-07T12:46:42.447599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Предсказание на тест данных для сабмишна\n",
    "final_test_pred_single_model = final_model_pipeline.predict(X_test)\n",
    "submission_single = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': final_test_pred_single_model})\n",
    "submission_single.to_csv('final_KFold_Catboost_Baseline.csv', index=False)\n",
    "submission_single.head()"
   ],
   "id": "27ff9107bfcd1732",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  121982.723142\n",
       "1  1462  157490.604484\n",
       "2  1463  189784.296524\n",
       "3  1464  192438.774384\n",
       "4  1465  176565.159645"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>121982.723142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>157490.604484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>189784.296524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>192438.774384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>176565.159645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:52:33.249490Z",
     "start_time": "2025-04-07T12:52:33.171420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kaggle BASELINE\n",
    "\n",
    "# 12879.10346"
   ],
   "id": "d9dab3fec7be6d4b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "efa1167d6750a138"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
